<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns:MadCap="http://www.madcapsoftware.com/Schemas/MadCap.xsd" MadCap:tocPath="Replication and Mirroring Guide|User's Guide" MadCap:InPreviewMode="false" MadCap:PreloadImages="false" MadCap:RuntimeFileType="Topic" MadCap:TargetType="WebHelp" lang="en-us" xml:lang="en-us" class="" MadCap:PathToHelpSystem="../../" MadCap:HelpSystemFileName="Default.xml" MadCap:SearchType="Stem">
    <head>
        <meta http-equiv="Content-Type" content="text/html; charset=utf-8" /><title>Mirroring and Replication Architecture</title>
        <link rel="icon" type="image/png" href="http://docs.raima.com/favicon.png" />
        <link href="../SkinSupport/MadCap.css" rel="stylesheet" />
        <link href="../Resources/Stylesheets/raima.css" rel="stylesheet" />
        <script src="../SkinSupport/MadCapAll.js" type="text/javascript">
        </script>
    </head>
    <body>
        <p class="MCWebHelpFramesetLink MCWebHelpFramesetLinkTop" style="display: none;"><a href="../../Default_CSH.htm#DFUG/Chapter2.htm" style="">Open topic with navigation</a>
        </p>
        <div class="MCBreadcrumbsBox_0"><span class="MCBreadcrumbsPrefix">You are here: </span><a class="MCBreadcrumbsLink" href="../dbDataFlow.htm">Replication and Mirroring Guide</a><span class="MCBreadcrumbsDivider"> &gt; </span><span class="MCBreadcrumbsSelf">User's Guide</span><span class="MCBreadcrumbsDivider"> &gt; </span><span class="MCBreadcrumbs">Mirroring and Replication Architecture</span>
        </div>
        <h1><a MadCap:generatedBookmark="TOC" name="Mirroring_and_Replication_Architecture"></a>Mirroring and Replication Architecture</h1>
        <p>The RDM&#160;Runtime always generates change log files as part of the process of committing a transaction. These log files can also be used, after being committed to the original database, as the basis for updating mirrors of the original database. Whenever a log is written to the original, the log is copied to locations where mirrors exist, and then are applied to the mirror databases. This re-use of log files means that the databases are byte-for-byte identical, and therefore must be used on computer architectures that have the same integer byte ordering. The use of page images in the log files means that transaction integrity is maintained and the recovery mechanism is very reliable.</p>
        <p>If replication is needed, a second artifact is required, an action log file. The action log file is generated by the runtime library when the configuration (shown below) indicates that the database is a replication master. The action log files, herein called replication log files, are transmitted to the locations of replication slaves through the same mechanism used for the change log files. A replication log differs from a change log in that it is a journal of actions (e.g. create record, connect record to set, delete record), where a change log is a set of page images as they exist after all of the actions have been completed at the end of a transaction.</p>
        <p>SQL&#160;updates can be generated from replication logs, but not from change logs.</p>
        <p>The mirroring process is primarily <i>asynchronous</i>, meaning that transactions applied to the master database will be propagated to the slaves as soon as possible. A <i>synchronous</i> mirroring process forces an acknowledgement from the slave that the transaction has been successfully applied prior to allowing the master to be updated again. Synchronous mirroring may be required in situations where the master and slave <i>must</i> be kept identical at all times, but it comes with a performance price. A restriction on synchronous mirroring is that a master may only have one synchronous slave, even if multiple slaves exist - all additional slaves are asynchronous.</p>
        <p>Replication is always asynchronous.</p>
        <p>Asynchronous mirroring and replication are designed to optimize the process of maintaining extra copies of a database, allowing the master to be updated at a maximum rate without being impeded by the performance of the slaves. There can be "bursts" of changes to the master, and time afterward for the slave(s) to catch up. It also provides for intermittent connections, meaning that a slave database may be "offline" for a period of time and can get caught up (sometimes called a "synchronize" operation) when it reconnects. Log files are kept with the master database for the purpose of allowing intermittent connections to catch up. The time a log file is kept with the master can be configured such that it is deleted after a certain age. Logs can also be deleted, oldest first, if the total space taken by them exceeds a configurable size.</p>
        <p>A slave may be on the same computer as the master (simply a different location), or on a different computer. The network connection can be a fast LAN within an office, or Internet from anywhere in the world (requires connectivity).</p>
        <p>A utility named <code>dbmirror</code> is used to move log files from the master to the slave database. A slave database configuration will also run <code>dbmirror</code> if it is a mirrored slave, or <code>dbrep</code> if it is a replicated <span class="MyVariablesProductShortName">RDM</span> slave, or <code>dbrepsql</code> if it is a replicated SQL&#160;slave.</p>
        <h2><a MadCap:generatedBookmark="TOC" name="Mirroring_Process"></a>Mirroring Process</h2>
        <p>Figure 12-1 below shows the generalized view of the mirroring process.</p>
        <p class="Caption">
            <img src="../Resources/Images/UsersGuide/UG-Fig-12-1_673x469.png" style="width: 673;height: 469;" />
            <br />Fig. 12-1 Mirroring Architecture</p>
        <p>The mirroring process is as follows:</p>
        <ol>
            <li value="1">Every transaction is committed to a master database by creating a log file (containing modified page images) in the database's directory. The log files are named after the transaction number they represent. Transactions are numbered serially with no gaps (see discussion about naming below).</li>
            <li value="2">The checkpoint process scans the directory for log files. When one or more new log files are found, they are "checkpointed" into the database. The entire process is safe and repeatable so that there will be no loss of data.</li>
            <li value="3">To facilitate mirroring, the checkpoint process will not delete used log files, but will rename them so that they can be found by the <code>dbmirror</code> process.</li>
            <li value="4">The slave <code>dbmirror</code> process requests the "next" log from the master <code>dbmirror</code> process. When it receives it, it sends it to the local TFS, if a TFS is running, for normal transaction processing. If a TFS is not running together with the slave <code>dbmirror</code>, there may or may not be a checkpointing process running. If there is, the presence of the log causes the checkpointer to copy these changes into the slave database. This is repeated forever, or until the dbmirror slave process is terminated.</li>
            <li value="5">The master <code>dbmirror</code> process searches the database directory for log files and responds to slave <code>dbmirror</code>s when certain log files are requested.</li>
            <li value="6">The master <code>dbmirror</code> can respond to any number of slave <code>dbmirror</code>s.</li>
        </ol>
        <p>Certain special conditions exist:</p>
        <ol>
            <li value="1">When a <i>first-time request</i> for a database comes from a slave <code>dbmirror</code>, the entire database must be copied to the slave. Then the normal process of applying incremental changes through log files applies.</li>
            <li value="2">The master checkpointer will have rules by which it deletes or cleans up log files:<ol style="list-style-type: lower-alpha;"><li value="1">If mirroring is disabled, the log files are deleted immediately after they are checkpointed.</li><li value="2">If mirroring is enabled, the checkpointer will rename them such that <code>dbmirror</code> will still find them, but they will not be checkpointed again.</li><li value="3">The checkpointer will be given time and/or disk space rules for log file cleanup. If the log files are beyond a certain age, they will be deleted, or if the total space on disk taken by the log files exceeds a given number, log files will be deleted.</li></ol></li>
            <li value="3">If a slave <code>dbmirror</code> requests a log that no longer exists (because of rule c above), it will be necessary to treat the request as a first-time request and send the entire database again. This situation can arise when a slave has an intermittent connection, or only connects to "synchronize" the database. There must be a balance between how long a slave may be disconnected and how long the log files will be kept by the master.</li>
        </ol>
        <p>Transaction log files are transient. They are kept as long as they are useful. When mirroring is disabled, their usefulness ends as soon as their contents are written to the database. The name of a log file represents it's current state. The list below shows the <i>life cycle</i> of a transaction log file:</p>
        <ol>
            <li value="1"><b>Creation</b> - while being created, the log file is opened in the database's directory and named <code><i>dbuserid</i>.prelog</code>, where <code>dbuserid</code> has been automatically assigned by the TFS, or has been requested through the <code><a href="../RM/api/d_dbuserid.htm">d_dbuserid</a></code> call. Logs being simultaneously created by different runtimes will always have different names.</li>
            <li value="2"><b>Commitment</b> - Once a prelog file has been completely written, it is <i>synced</i>, meaning that all of its contents are written and committed to disk. Should the computer fail after this moment, the contents on the disk will be correct and complete. After the sync operation, the file is renamed. The renaming makes it visible to the checkpointing process. If a computer failure occurs after the sync but before the rename, then the transaction will not be considered to be committed, and will never be found in the database after the TFS restarts. In this situation, the runtime submitting the transaction will not be notified that the transaction was successfully committed. The name of the log file will be the transaction ID (an 8 hexadecimal digit number) with a <code>.log</code> type, for example, <code>0000015d.log</code>. The log files are named strictly sequentially, and are always applied to the database in numeric order.</li>
            <li value="3"><b>Checkpoint</b> - The checkpoint process will find and apply the contents of a log file to the database on a regular basis. Once a log file (and any others that may be batched together) has been written to the database and the database files have been synced, the log files are no longer required by this TFS. If mirroring is disabled, the log file(s) are deleted now. If not, the log files are renamed again by adding a .arch suffix, for example, <code>0000015d.log.arch</code>. The dbmirror process looks for transactions in numeric order.</li>
            <li value="4"><b>Cleanup</b> - If archived log files exist, there should be time or space restrictions that determine when they can be deleted.</li>
        </ol>
        <p>See Figure 12-2 below:</p>
        <p class="Caption">
            <img src="../Resources/Images/UsersGuide/UG-Fig-12-2_448x370.png" style="width: 448;height: 370;" />
            <br />Fig. 12-2 Transaction Log Life Cycle</p>
        <h2><a MadCap:generatedBookmark="TOC" name="Replication_Process"></a>Replication Process</h2>
        <p>Figure 12-3 below shows the generalized replication flow.</p>
        <p class="Caption">
            <img src="../Resources/Images/UsersGuide/UG-Fig-12-3_675x507.png" style="width: 675;height: 507;" />
            <br />Fig. 12-3 Replication Architecture</p>
        <p>Note that figures 12-1 and 12-3 are similar in the master database domain. While all components are not shown in the figures, both use the same dbmirror utility to manage the transmission of log files, whether they are change logs or replication logs. All logs are placed into the same location to be found by dbmirror when they are ready. The process of copying the initial database to a slave is the same. The main difference is how the log file is consumed on the slave side.</p>
        <p>Replication preparation is as follows for replication to an <span class="MyVariablesProductShortName">RDM</span> database:</p>
        <ol>
            <li value="1">Start with an existing <span class="MyVariablesProductShortName">RDM</span> database. DDL&#160;has been defined and compiled with <code><a href="../util/ddlp.htm">ddlp</a></code>. This database may be new, or it may be in active operation.</li>
        </ol>
        <p>Replication preparation is as follows for replication to an <i>RDM&#160;Server</i> database:</p>
        <ol>
            <li value="1">Start with an existing <span class="MyVariablesProductShortName">RDM</span> database. DDL&#160;has been defined and compiled with <code><a href="../util/ddlp.htm">ddlp</a></code>. This database may be new, or it may be in active operation.</li>
            <li value="2">Create SQL&#160;DDL from the existing database definition. See the <code><a href="#schemaxlate">schemaxlate</a></code> utility definition below. It will generate a text file containing the SQL&#160;DDL corresponding to the <span class="MyVariablesProductShortName">RDM</span> database definition.</li>
            <li value="3">Use the SQL&#160;database procedure to generate a new database from the SQL&#160;DDL.</li>
            <li value="4">Create an ODBC&#160;data source for the SQL&#160;database (Windows only).</li>
            <li value="5">Set the RDSLOGIN&#160;environment variable to identify the ODBC DSN (Windows) or RDM&#160;Server name (Unix), username and password.</li>
        </ol>
        <p>The replication process is as follows:</p>
        <ol>
            <li value="1">For every transaction committed to a master database, a replication log is also generated. The log is only generated if a configuration option is turned on. See <a href="#12.5">Mirroring Setup</a> below. The names for the replication log files are also based on the same transaction numbers as the change log files.</li>
            <li value="2">The slave <code>dbrep</code> or <code>dbrepsql</code> process requests the "next" log from the master <code>dbmirror</code> process. When it receives it, it stores it to the local database directory under the document root.<ol style="list-style-type: lower-alpha;"><li value="1">If <code>dbrep</code> is running, the log will be processed into the slave <span class="MyVariablesProductShortName">RDM</span> database.</li><li value="2">If <code>dbrepsql</code> is running, the log will be converted into SQL&#160;and submitted to the SQL&#160;database that has been selected.</li></ol><p>This is repeated forever, or until the slave process is terminated.</p></li>
            <li value="3">The master <code>dbmirror</code> process searches the database directory for log files and responds to slaves when certain log files are requested.</li>
            <li value="4">The master <code>dbmirror</code> can respond to any number of slaves.</li>
        </ol>
        <p>Certain special conditions exist:</p>
        <ol>
            <li value="1">When a <i>first-time request</i> for a database comes from a slave process, the entire database must be copied to the slave. Then the normal process of applying incremental changes through log files applies.</li>
            <li value="2">The master checkpointer will have time and/or disk space rules for log file cleanup. If the log files are beyond a certain age, they will be deleted, or if the total space on disk taken by the log files exceeds a given number, log files will be deleted.</li>
            <li value="3">If a slave process requests a log that no longer exists (because of rule 2 above), it will be necessary to treat the request as a first-time request and send the entire database again. This situation can arise when a slave has an intermittent connection, or only connects to "synchronize" the database. There must be a balance between how long a slave may be disconnected and how long the log files will be kept by the master.</li>
        </ol>
        <h2><a MadCap:generatedBookmark="TOC" name="Database_Storage_Location"></a><a name="DBStorageLoc"></a>Database Storage Location</h2>
        <p>A slave database resides in a slightly different location relative to the TFS document root. All databases mirrored or replicated from the same TFS will be under a subdirectory named after the source TFS and its port. An example is shown below for a mirror site that keeps copies of <code>sales</code> and <code>invntory</code>:</p><pre xml:space="preserve">MASTER                                 SLAVE
TFS Name: acct.raima.com               TFS Name: RLM-lptp
Document Root: c:\RDM\databases	Document Root: d:\db
------------------------               ------------------
c:\RDM\databases\                      d:\db\
    invntory\                              <b>acct.raima.com-<span class="MyVariablesDefaultPort">21553</span>\</b>
        invntory.dbd                           invntory\
        invntory.d01                               invntory.dbd
        ...                                        invntory.d01
    sales\                                         ...
        sales.dbd                              sales\
        sales.d01                                  sales.dbd
        ...                                        sales.d01
                                                   ...</pre>
        <p>Opening the master database is also different from opening the slave. The open call must include the path to the slave database. Slave databases are read-only and cannot be opened for updating. Assuming that a program is running such that the databases are found on <code>localhost</code>:</p><pre xml:space="preserve">On acct.raima.com                      On RDM-lptp
-----------------                      -----------
d_open("sales;invntory", "s", task);   d_open("acct.raima.com-<span class="MyVariablesDefaultPort">21553</span>/invntory", "r", task);
                                       d_iopen("acct.raima.com-<span class="MyVariablesDefaultPort">21553</span>/sales", task);</pre>
        <p>Note that throughout this document the notation for identifying any TFS is <code><i>hostname</i>:port</code>, where <code>:port</code> can be omitted if the default port, <span class="MyVariablesDefaultPort">21553</span>, is used. We recommend using the default port for everything unless multiple TFSs are running on the same computer. However, when a directory is created for the sake of storing a mirrored or replicated database, the port is not optional. Therefore the default port will be made a part of the directory name even though it may be left off of TFS references. For example, if the <code>dbget</code> utility is used to initiate the mirroring of a database as follows:</p><pre xml:space="preserve">dbget -b poi@tfs.raima.com</pre>
        <p>which is using the default port, then the local directory created under the document root to store the database will be:</p><pre xml:space="preserve">
            <i>docroot</i>/tfs.raima.com-<span class="MyVariablesDefaultPort">21553</span>/poi</pre>
        <p>It is always fine to explicitly include the default port:</p><pre xml:space="preserve">dbget -b poi@tfs.raima.com:<span class="MyVariablesDefaultPort">21553</span></pre>
        <hr MadCap:conditions="Default.ScreenOnly" width="100%" size="0" align="center" />
        <p MadCap:conditions="Default.ScreenOnly" style="font-size: 8pt;"><span class="MyVariablesCopyright">Copyright Â© 2012, Raima Inc. All rights reserved.</span>
        </p>
        <script type="text/javascript" src="../SkinSupport/MadCapBodyEnd.js">
        </script>
        <p class="MCWebHelpFramesetLink MCWebHelpFramesetLinkBottom" style="display: none;"><a href="../../Default_CSH.htm#DFUG/Chapter2.htm" style="">Open topic with navigation</a>
        </p>
    </body>
</html>