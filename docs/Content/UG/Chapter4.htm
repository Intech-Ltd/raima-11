<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns:MadCap="http://www.madcapsoftware.com/Schemas/MadCap.xsd" MadCap:tocPath="Native API|User's Guide" MadCap:InPreviewMode="false" MadCap:PreloadImages="false" MadCap:RuntimeFileType="Topic" MadCap:TargetType="WebHelp" lang="en-us" xml:lang="en-us" class="" MadCap:PathToHelpSystem="../../" MadCap:HelpSystemFileName="Default.xml" MadCap:SearchType="Stem">
    <head>
        <meta http-equiv="Content-Type" content="text/html; charset=utf-8" /><title>Database Design</title>
        <link rel="icon" type="image/png" href="http://docs.raima.com/favicon.png" />
        <link href="../SkinSupport/MadCap.css" rel="stylesheet" />
        <link href="../Resources/TableStyles/BasicTwoCol.css" rel="stylesheet" />
        <link href="../Resources/TableStyles/ArgsTwoCol.css" rel="stylesheet" />
        <link href="../Resources/Stylesheets/raima.css" rel="stylesheet" />
        <script src="../SkinSupport/MadCapAll.js" type="text/javascript">
        </script>
    </head>
    <body>
        <p class="MCWebHelpFramesetLink MCWebHelpFramesetLinkTop" style="display: none;"><a href="../../Default_CSH.htm#UG/Chapter4.htm" style="">Open topic with navigation</a>
        </p>
        <div class="MCBreadcrumbsBox_0"><span class="MCBreadcrumbsPrefix">You are here: </span><a class="MCBreadcrumbsLink" href="../dbCore.htm">Native API</a><span class="MCBreadcrumbsDivider"> &gt; </span><a class="MCBreadcrumbsLink" href="dbUG.htm">User's Guide</a><span class="MCBreadcrumbsDivider"> &gt; </span><span class="MCBreadcrumbs">Database Design</span>
        </div>
        <h1 class="firstHeading"><a MadCap:generatedBookmark="TOC" name="Database_Design"></a>Database Design</h1>
        <h2 class="Heading2"><a MadCap:generatedBookmark="TOC" name="4.1_Introduction_..17"></a>4.1 Introduction </h2>
        <p>A database design is a description of the data that will be stored in a database and the relationships that will exist within that data. The design of a particular database is driven by the requirements of the application it will support and is therefore a major part of the total application design process. </p>
        <p>Our purpose in this section is to provide you with the information necessary to design <span class="MyVariablesProductShortName">RDM</span> databases. If you carefully study this section and the example database design, you should be able to design a workable <span class="MyVariablesProductShortName">RDM</span> database, even if you have no database design experience. </p>
        <p>The section begins with a detailed description of the <span class="MyVariablesProductShortName">RDM</span> Database Definition Language (DDL). Each DDL statement is explained and illustrated through examples. The operation of the DDL processor is explained followed by a section on database design considerations. The final section builds on the <code>tims</code> database example introduced in <a href="Chapter3.htm">Operational Overview</a> by expanding the requirements and describing how the database design supports those requirements. </p>
        <h2 class="Heading2"><a MadCap:generatedBookmark="TOC" name="4.2_Database_Definition_Language_(DDL)"></a><a name="4.2"></a>4.2 Database Definition Language (DDL) </h2>
        <h3 class="Heading3"><a MadCap:generatedBookmark="TOC" name="4.2.1_DDL_Basics"></a><a name="4.2.1"></a>4.2.1 DDL Basics </h3>
        <p>An <span class="MyVariablesProductShortName">RDM</span> database design is specified in the Database Definition Language. One DDL specification file exists for each <span class="MyVariablesProductShortName">RDM</span> database. In general there is one database per application, although some applications may require the use of several databases. (The <a href="#4.4.1">Logical Design Considerations</a> section discusses multiple database design.) A DDL specification identifies the database, defines the files that comprise the database, and contains declarations for all record types, data and key fields, and set relationships that will exist in the database. </p>
        <p>Below is an example DDL specification. It is an expanded version of the checking account schema given in the <a href="Chapter3.htm">Operational Overview</a>. It is provided here to illustrate some additional DDL statements and to serve as a baseline example in the descriptions that follow. A complete DDL syntax summary can be found in <a href="../util/ddlp.htm">Utility Descriptions</a> of the <span class="MyVariablesProductShortName">RDM</span> Reference Manual. </p><pre>database ckngacct[512]
{
    data file datfile = "chkg.dat" contains budget, check;
    key file[1024] keyfile1 = "chkg.k01" contains code;
    key file[2048] keyfile2 = "chkg.k02" contains check_no, check_date;

    record budget
    {
        unique key char  code[6];
                   char  cat_desc[48];
                   float alloc;
                   float balance;
    }

    record check
    {
        unique key int32_t check_no;
               key int32_t check_date;
                   char    paid_to[48];
                   float   amount;
    }

    set transactions
    {
        order last;
        owner budget;
        member check;
    }
}</pre>
        <p>The DDL specification is stored in a text file and is created using your usual text editor. Input is free form with comments specified, as in C, between /* */ pairs. </p>
        <p class="Notes">NOTE:&#160;Nested comments are not allowed.</p>
        <p>Identifiers are used to name the database, files, records, fields, and sets. They are formed, as in C, from any combination of letters, digits, and underscores (_) beginning with a letter. </p>
        <p>File, record, and set statements may be interspersed provided that: </p>
        <ul>
            <li style="font-family: Arial;" value="1">Data and key file statements are specified ahead of the declarations of the records and key fields they contain. </li>
            <li style="font-family: Arial;" value="2">The declarations of set owner and member record types are specified ahead of their respective set declarations. </li>
        </ul>
        <p>General practice is to place all file statements first, followed by all record type declarations, followed by all set declarations. The <code><a href="../util/ddlp.htm">ddlp</a></code> can, optionally, produce a record, field, and set name cross-reference listing to help you locate names contained in a long DDL specification (see&#160; <a href="#4.3">DDL Processor Operation</a>). </p>
        <h3 class="Heading3"><a MadCap:generatedBookmark="TOC" name="4.2.2_Database_Statement"></a>4.2.2 Database Statement </h3>
        <p class="Heading">Syntax: </p><pre class="Grammar" xml:space="preserve">database_stmt:
 		<b>database</b>   <![CDATA[ ]]><i>db_name</i> 
			[ '<b>[</b>' <i>pgsize</i> '<b>]</b>' ] [<b>inmemory</b> [<b>persistent</b> |&#160;<b>volatile</b> |&#160;<b>read</b>]] [<b>dba4</b> |&#160;<b>dba8</b>]
                '<b>{</b>
                        file_stmt [file_stmt]...
                        record_stmt [record_stmt]...
                        [set_stmt [set_stmt]...]
                '<b>}</b>'</pre>
        <p class="Heading">Description: </p>
        <p>The <b>database</b> statement is used to specify the name of the database and, optionally, the default page size of all files. </p>
        <p>The name of the database <i>dbname</i> is an identifier and is used by <code>ddlp</code> to form the names of the database dictionary file and the C or C++ header file. The dictionary file is named <code><i>dbname</i>.dbd</code> and the header file is named <code><i>dbname</i>.h</code>. Note that the length of this name can be up to 31 characters. </p>
        <p>The database name, <i>dbname</i>, is passed to function <code href="../RM/api/d_open.htm">d_open</code> to identify the name of the database to be opened and subsequently accessed. It is also passed to utilities such as <code href="../util/initdb.htm">initdb</code> to identify the database to be operated on (initialized) by the particular utility. </p>
        <p MadCap:conditions="">The <span class="MyVariablesProductShortName">RDM</span> <![CDATA[ ]]><b>data</b>, <b>vardata</b>, <b>blob</b> and <b>key</b> files are blocked or divided into fixed-length pages, each containing as many record or key occurrences as will fit on a page. The <i>pgsize</i> parameter determines the default database page size in bytes. This value should, for performance reasons, always be a multiple of the basic block size for your operating system (a multiple of 512 will work for most systems). If not specified, the default database page size is 1024 bytes, but will be the first number divisible by 512 that is large enough to contain the largest record.</p>
        <p MadCap:conditions="">By default the database files are created on the file system, but you can specify that they should be created in memory instead, by adding the <b>inmemory</b> qualifier to the database definition. The <b>read</b>, <b>persistent </b>and <b>volatile</b> options control whether the database files are read from disk when the database is opened, and whether they are written to disk when the database is closed.</p>
        <p>For <b>inmemory</b> databases, the default database address size is <b>dba4</b> which limits the maximum rows per table to 16.7 million.&#160;Otherwise, the default database size is <b>dba8</b> which provides a maximum of 281.4 trillion rows per table.</p>
        <p class="Heading">Examples: </p><pre>database <i>ckngacct</i>[512] { ... } </pre>
        <p>For the checking account example, the name of the database is <i>ckngacct</i> and it has a default database page size of 512 bytes. The name of the dictionary file created by <code href="../util/ddlp.htm">ddlp</code> is <code>ckngacct.dbd</code>. The name of the C header file created by <code>ddlp</code> is <code>ckngacct.h</code>. </p><pre>database <i>acctsrec</i> { ... } </pre>
        <p>The above is a possible database statement for an accounts receivable database. Since no page size parameter is specified the default database page size is 1024 bytes. The dictionary will be stored in file <code>acctsrec.dbd</code> and the C header file will be named <code>acctsrec.h</code>. </p>&#160;<h3><a MadCap:generatedBookmark="TOC" name="4.2.3_File_Declarations"></a><a name="4.2.4"></a>4.2.3 File Declarations</h3><pre class="Grammar" xml:space="preserve">file_stmt:
 		<b>data file</b> ['<b>[</b>' <i>pgsize</i> '<b>]</b>'] file_spec [<b>maxslots =</b><i>slots</i>]
                        <b>contains</b>   <![CDATA[ ]]><i>recname</i>[, <i>recname</i>]... '<b>;</b>'
    &#160;&#160;&#160;&#160;|&#160;&#160;&#160;&#160;&#160;&#160;<b>key file</b> ['<b>[</b>' <i>pgsize</i> '<b>]</b>'] file_spec
                        <b>contains</b> [<i>recname</i>.]<i>keyfld</i>[, [<i>recname</i>.]<i>keyfld</i>]... '<b>;</b>'
        |       <b>hash file</b> ['<b>[</b>' <i>pgsize</i> '<b>]</b>'] file_spec <b>size =</b><i>hashtablesize</i>   <![CDATA[
                        ]]><b>contains</b> [<i>recname</i>.]<i>blobfld</i>[, [<i>recname</i>.]<i>blobfld</i>]... '<b>;</b>'
        |       [<b>compact</b>] <b>vardata file</b> ['<b>[</b>' <i>pgsize</i> '<b>]</b>'] file_spec
                        <b>contains</b> [<i>recname</i>.]<i>varfld</i>[, [<i>recname</i>.]<i>varfld</i>]... '<b>;</b>' 
        |       <b>blob file</b> ['<b>[</b>' <i>pgsize</i> '<b>]</b>'] file_spec
                        <b>contains</b> [<i>recname</i>.]<i>blobfld</i>[, [<i>recname</i>.]<i>blobfld</i>]... '<b>;</b>' </pre><pre class="Grammar" xml:space="preserve">file_spec:
                [<b>fileid =</b>] "<i>filename</i>" [file_option[, file_option]...]</pre><pre class="Grammar" xml:space="preserve">file_option:
                <b>inmemory</b> [<b>persistent</b> |&#160;<b>volatile</b> |&#160;<b>read</b>]
        |       <b>maxpgs =</b><i>pages</i>
        |       <b>pagesize =</b><i>pgsize</i></pre><p class="Heading">Description: </p><p>File declarations identify the physical files to contain the data stored in the database. </p><ul style="font-family: Arial;"><li style="font-family: Arial;" value="1">The <b>data file</b> statement defines a file that will contain the occurrences of one or more record types. </li><li style="font-family: Arial;" value="2">The <b>key file</b> statement defines a file that will contain the index for one or more <b>key</b> fields.</li><li value="3">The <b>hash file</b> statement defines a file that will contain the hash index for one <b>key</b> field.</li><li style="font-family: Arial;" MadCap:conditions="" value="4">The <b>vardata file</b> statement defines a file that will contain the additional data for one or more <b>varchar</b> fields.</li><li style="font-family: Arial;" MadCap:conditions="" value="5">The <b>blob file</b> statement defines a file that will contain the additional data for one or more <b>blob_id</b> fields.</li></ul><p MadCap:conditions="">The <span class="MyVariablesProductShortName">RDM</span> <![CDATA[ ]]><b>data</b>, <b>vardata</b>, <b>blob</b> and <b>key</b> files are blocked or divided into fixed-length pages, each containing as many record or key occurrences as will fit on a page. Each slot contains a record occurrence, a key value, or part of a <b>varchar</b> or <b>blob_id</b> field. The optional <code>pgsize</code> parameter specifies the page size for the file. If not specified, the page size for the file will be the default database page size. This value should always be a multiple of the basic block size of your operating system (a multiple of 512 will work for most systems). Otherwise, the operating system's file access performance will be impaired.</p><p MadCap:conditions="">The hash files contains the hash table. The <b>hashtablesize</b> is required parameter in the DDL&#160;definition and should be equivalent to the maximum expected entries in the table. Specifying a value that is less than that may impact performance.</p><p MadCap:conditions="">Note that more than one entity of the same type may be stored in the same file. That is, multiple record types can reside in the same file, multiple key types can reside in one file, etc. For most designs, it is best to put each entity into its own file. Since a file will always have the same size pages, and the same size slots within those pages, it must select the slot size based on the largest entity that will be stored in the file. For example, if a large record type and a small record type are stored in the same file, the small record instances will each be stored into slots that fit the larger records, causing space to be wasted.</p><p>The name of the file, <code>filename</code>, is a string enclosed in quotation marks (") containing the physical (operating system) name of the file. The name of the file is not qualified (that is, it does not include a directory name).</p><p class="Notes">NOTE: Earlier versions of <span class="MyVariablesProductShortName">RDM</span> (prior to version 10) allowed file names to be prefixed with relative or absolute paths. This is not allowed now because all database files are placed in a unique directory within the document root of the TFS.</p><p>Associated with a database file is an optional field, <code>fileid</code>, which is used to identify files within an application program independent of the physical name of the file. It is intended to be used for dynamic initialization of individual files using the <a href="../RM/api/d_initfile.htm">d_initfile</a> function (<a href="Chapter5.htm#5.2.3">Dynamic Database Initialization</a>).</p><p MadCap:conditions=""><b>Vardata</b> files contain the string data associated with <b>varchar</b> fields, divided up into fixed-length slots. By default, each slot contains the database address of its "owner" record occurrence. </p><p MadCap:conditions=""><b>Vardata</b> files defined as <b>compact</b> will not contain database addresses referring back to the "owner" records. This saves some space, making the files smaller, but it may make data recovery impossible in the event of database corruption. It also limits the ability of the <code href="../util/dbrepair/UTL/dbcheck.htm"><a href="../util/dbrepair/UTL/dbcheck.htm">dbcheck</a></code> program to test the integrity of the database.</p><p MadCap:conditions="">BLOB files contain the data associated with the <b>blob_id</b> fields. The BLOB&#160;is stored as a linked list of fixed-length pages. The record containing the <b>blob_id</b> field stores the address of the first page of the BLOB&#160;data in the blob file. There is a one-to-one correspondence between the BLOB&#160;data and the record occurrence containing the <b>blob_id</b> field referencing the BLOB&#160;data.</p><table style="width: 100%;border-left-style: solid;border-left-width: 1px;border-left-color: #c0c0c0;border-right-style: solid;border-right-width: 1px;border-right-color: #c0c0c0;border-top-style: solid;border-top-width: 1px;border-top-color: #c0c0c0;border-bottom-style: solid;border-bottom-width: 1px;border-bottom-color: #c0c0c0;border-collapse: collapse;margin-left: 0;margin-right: auto;mc-table-style: url('../Resources/TableStyles/BasicTwoCol.css');" class="TableStyle-BasicTwoCol" cellspacing="0"><col style="width: 140px;" class="Column-Column1" /><col class="Column-Column2" style="width: 745px;" /><thead><tr MadCap:conditions="" class="Head-Header1"><th class="HeadE-Column1-Header1">In-memory <br />Keywords</th><th class="HeadD-Column2-Header1">Description</th></tr></thead><tbody><tr MadCap:conditions="" class="Body-Body1"><td class="BodyE-Column1-Body1"><b>persistent</b></td><td class="BodyD-Column2-Body1"><p>The contents of the in-memory "file" will be written back to the specified disk file when the last application closes the database.</p></td></tr><tr MadCap:conditions="" class="Body-Body1"><td class="BodyE-Column1-Body1"><b>read</b></td><td class="BodyD-Column2-Body1">The contents of the in-memory "file" will be read from the specified disk file when the first application opens the database.</td></tr><tr MadCap:conditions="" class="Body-Body1"><td class="BodyE-Column1-Body1"><b>volatile</b></td><td class="BodyD-Column2-Body1">The in-memory "file" will not be backed by a disk file.</td></tr><tr MadCap:conditions="" class="Body-Body1"><td class="BodyB-Column1-Body1"><b>maxpgs</b></td><td class="BodyA-Column2-Body1">Specifies the maximum size of the "file".</td></tr></tbody></table><p>The <b>maxslots</b> parameter specifies the maximum number of slots (record instances) <span class="MyVariablesProductShortName">RDM</span> will allow in the data file. By default this value is determined by the size of database addresses in the database. For example, in a database with 32-bit database addresses 24 bits are used for the record slot number, implying a maximum of 16.7 million slots per file. The <b>maxslots</b> value can be set to any positive value smaller than this default. For files containing <b>circular</b> records the <b>maxslots</b> value must be specified explicitly in the file definition.</p><p>All record types defined in the DDL must be contained in a data file. All occurrences of the record types listed in the contains clause will be stored in that file. Occurrences of a given record type can only be stored in a single file (except that variable-length fields will be stored in <b>vardata</b> files). Each page in the data file consists of one or more fixed-length record. Each page of the record slot is based upon the size of the largest record type contained in the file.                                                      <![CDATA[ ]]></p><p>A special system-defined record named <b>system</b> may be listed as the first record type in the <b>contains</b> clause of one of the data files. Only one occurrence of the system record exists in the database. It is not mandatory to use a system record, but if it is defined by including it in a file and making it the owner of one or more sets, it will be automatically created when the database is initialized. It is used as the owner of any number of sets to provide the means for records to be connected to the top or root of the network. When the database is opened, the current record and the current owners of all system-owned sets are initialized to the system record. </p><p>All key fields defined in the DDL must be contained in a key file. All occurrences of the key fields listed in the <b>contains</b> clause will be stored in the file. Occurrences of a given key type can only be stored in a single file. Each page in the key file consists of one or more fixed-length key slots. The size of the key slot is based upon the size of the largest key field contained in the file. Smaller key fields will occupy the same slots, thus leaving unused space. You can define all key fields to be contained in one file or you can have a separate key file for each individual key field. The choice is yours. </p><p>The <a href="#4.4.2">Physical Design Considerations</a> section provides some guidelines to help you determine the best file organization for your particular application. </p><p class="Heading">Examples: </p><pre>data file datfile = "chkg.dat" contains budget, check;
key file[1024] keyfile1 = "chkg.k01" contains code;
key file[2048] keyfile2 = "chkg.k02" contains check_no;</pre><p>The checking account database consists of one data file and two key files. The data file identified as
<code>datfile</code> contains occurrences of both the budget and check record types in the physical file named
<code>chkg.dat</code>. From the database statement the page size for <code>datfile</code> is 512 bytes. The key file identified a <code>keyfile1</code> has a page size of 1024 bytes and contains the index for key field <code>code</code> in file <code>chkg.k01</code>. Key file <code>keyfile2</code> has a page size of 2048 bytes and contains the index for key field <code>check_no</code> in file <code>chkg.k02</code>. </p><pre>key file "invnt.k01" contains stock.id_code;
key file "invnt.k02" contains bkorder.id_code;</pre><p class="Heading3">The above example shows duplicated key names that are qualified by the record type in which they are defined. When duplicate field names are used, it is necessary to use the <code>-d</code> option with the <code href="../util/ddlp.htm">ddlp</code> command (see&#160; <a href="#4.3">DDL Processor Operation</a>).</p><h3 class="Heading3"><a MadCap:generatedBookmark="TOC" name="4.2.4_Record_Declarations"></a><a name="4.2.5"></a>4.2.4 Record Declarations</h3><p class="Heading">Syntax: </p><pre class="Grammar" xml:space="preserve">record_stmt:
 		[<b>static</b>] [<b>circular</b>] <b>record</b>   <![CDATA[ ]]><i>recname</i> '<b>{</b>'
                        field_stmt [field_stmt]...
                        [comkey_stmt [comkey_stmt]...]
                '<b>}</b>'</pre><p class="Heading">Description:</p><p>The <b>record</b> statement defines a group of related data fields named <i>recname</i> that will be stored and
accessed together on the database as a single unit. The record declaration consists of zero or more field

statements followed by zero or more compound key statements. A record specification with no data fields is valid, and often is used in the implementation of many-to-many sets (see <a href="#4.4.1.2">Use of Sets</a>).</p><p>The <code href="../util/ddlp.htm"><a href="../util/ddlp.htm">ddlp</a></code> utlility will use the identifier <i>recname</i> to create two C identifiers in the <code>dbname.h</code> file. A <code>struct</code> named <span class="code">recname</span>, containing the C declarations for the data fields defined in the record
will be declared
in <span class="code"><i>dbname</i>.h</span>. The name of the <span class="code">struct</span> will identically match the name of the record as specified in the DDL. An upper-case form of <i>recname</i> will define an integer constant record number, which serves as a record type identifier to be passed to those <span class="MyVariablesProductShortName">RDM</span> runtime functions that manipulate records. Record names, therefore, should never be specified entirely in upper-case.</p><p>The <b>static</b> attribute specifies that the records are never updated when the database is opened in shared mode. This allows the <span class="MyVariablesProductShortName">RDM</span>runtime to optimize access to the static record occurrence, yielding better performance. Static records are used for storing information such as menus, data entry forms, help screens, system messages, coded value information, etc. Multi-user database programs are not required to place locks on this data in order to access it. Static records can only be modified when the database is opened in exclusive access mode. The data and key files containing static record information can only contain static data. The <b>system</b> record is a special case and can be included in a data file that contains either static or not static records. Static records can only be used in sets which themselves are not modified except in exclusive access mode.</p><p>If a record type is defined as <b>circular</b>, record slots are automatically re-used once the maximum number of slots has been stored. A <b>circular</b> record must be the only record type in its file. The definition of this file must include a <b>maxslots</b> value specifying the maximum number of slots in the file. Once this number of record instances has been stored, <span class="MyVariablesProductShortName">RDM</span> will overwrite the oldest record instance whenever a new one is created. Instances of <b>circular</b> record types cannot be explicitly deleted with functions d_delete or d_disdel.</p><p class="Heading">Example:</p><pre xml:space="preserve">record check {
    unique key int check_no;
    int check_date;
    char paid_to[49];
    float amount;
}</pre><p>The <code>check</code> record type in the checking account database contains two integer fields (one of which is a
key), a character string field, and a floating point field. File <code>chkgacct.h</code> will contain the following
definitions associated with the check record type:              </p><pre xml:space="preserve">struct check { 
    int check_no;
    int check_date;
    char paid_to[49];
    float amount;
}; 
#define CHECK&#160;10001
</pre><p>Record <code>trans</code> below contains two compound key field declarations. (For more information, see <a href="#4.4.1.1">Use of
Keys</a>).</p><pre xml:space="preserve">record trans {
    unique key int checkno;
    int trdate;
    char vendid[8];
    long amount;
    compound key tr_key {
        trdate descending;
        vendid ascending;
    }
    compound key ven_chks {
        vendid; checkno;
    }
}

</pre><p class="Heading3">Below are two record types and a set that might be defined for a multi-user data entry, forms management system. Note that both records are declared to be static, since during normal operation of an application using the forms manager, form and field records are not modified.</p><pre class="Heading3">static record form {
    unique key char form_id[11];
}

static record field {
    unique key char field_id[21]; /* Display name of field */
    int id_row;      /* Row where field_id displayed */
    int id_col;      /* Column where field_id displayed /
    int data_row;    /* Row where data starts */
    int data_col;    /* Column where data starts */
    int field_len;   /* Editable field length */
    char required;   /* Required field */
    int edit_fcn;    /* Editing function called on entry */
    int disp_fcn;    /* Display function called on output /
    int rtype;       /* Record type containing the field */
    long ftype;      /* RDM field type */
}

set form_fields {
    order last;
    owner form;
    member field;
}</pre><h3 class="Heading3"><a MadCap:generatedBookmark="TOC" name="4.2.5_Field_Declarations"></a>4.2.5 Field Declarations </h3><h4 class="Heading4"><a MadCap:generatedBookmark="TOC" name="Data_Fields"></a>Data Fields </h4><p class="Heading">Syntax: </p><pre class="Grammar" xml:space="preserve">field_stmt:
                [key_stmt] field_type_stmt '<b>;</b>'
        |       [key_stmt] <b>struct</b> '<b>{</b>'
                        type_stmt <i>fldname</i> array_stmt '<b>;</b>'
                        [ type_stmt <i>fldname</i> array_stmt '<b>;</b>' ]...
                '<b>}</b>' <i>fldname</i> array_stmt '<b>;</b>'
</pre><pre class="Grammar" xml:space="preserve">key_stmt:
                [<b>optional</b>] [<b>unique</b>] <b>key</b> [ '[' <i>keylen</i> ']' ]
        |       <b>hash</b> [ '<b>[</b>' <i>keylen</i> '<b>]</b>' ]</pre><pre class="Grammar" xml:space="preserve">field_type_stmt:
                type_stmt <i>fldname</i> array_stmt
        |       <b>blob_id</b>    <![CDATA[  ]]><i>fldname</i>
        |      &#160;{<b>varchar</b>&#160;|&#160;<b>varwchar</b> |&#160;<b>varbinary</b>} '<b>[</b>' [<i>minsize</i>,] <i>maxsize</i> '<b>]</b>'
</pre><pre class="Grammar" xml:space="preserve">array_stmt:
                [ '<b>[</b>' <i>dim</i> '<b>]</b>' [ '<b>[</b>' <i>dim2</i> '<b>]</b>' [ '<b>[</b>' <i>dim3</i> '<b>]</b>' ] ] ]</pre><pre class="Grammar" xml:space="preserve">type_stmt:
                [<b>unsigned</b>] { <b>int</b> |&#160;<b>short</b> |&#160;<b>long</b> |&#160;<b>char</b>&#160;}
        |       <b>wchar</b> |&#160;<b>wchar_t</b>
        |       <b>int16_t</b> |&#160;<b>int32_t</b> |&#160;<b>int64_t</b>
        |       <b>uint8_t</b> |&#160;<b>uint16_t</b> |&#160;<b>uint32_t</b> |&#160;<b>uint64_t</b>
        |       <b>float</b> |&#160;<b>double</b>
        |       <b>DB_ADDR</b> |&#160;<b>DB_ADDR4</b> |&#160;<b>DB_ADDR8</b></pre><p class="Heading">Description: </p><p>The <i>fldname</i> is an identifier that names the particular data field. Field names may not duplicate record or set names, nor by default other field names. </p><p>The syntax for a data field statement is similar to, although not as general as, a C data declaration. In fact, most of the basic data types in C are directly supported in the DDL. Arrays of any type are available, where <i>dim</i> specifies the size of a given array dimension. </p><p>One-dimensional character arrays are treated by the <span class="MyVariablesProductShortName">RDM</span> runtime functions as C strings. Thus, these fields should always be terminated by a null byte, and the length as specified in the field declaration should include the null byte. If a one-dimensional character array is needed that is not intended to be treated like a string (for example, a byte array), it should be declared as a two-dimensional array where the second dimension is one. </p><p>A data field that is also to be used as a key to the record has the <b>key</b> attribute. Key field values are stored on the key file in the natural order based on the data type. If only unique keys are allowed then the field should be qualified as a <b>unique key</b> field. The maximum length of a key field is 234 bytes. Fields defined as a <b>unique key</b> must contain a value that does not already exist on the key file at the time its associated record is entered into the database. If a record is entered (or modified) with a duplicate value in a unique key field, the status code S_DUPLICATE is returned and the record is not entered (or modified). </p><p>The <b>hash key</b> uses a universal hash algorithm (see Hashing vectors in <a href="http://en.wikipedia.org/wiki/Universal_hashing">Wikipedia's Universal Hashing</a> article)&#160;to generate a 64 bit hash value. Hash keys are always unique. If a record is entered (or modified) with a duplicate value in a hash key field, the status code S_DUPLICATE is returned and the record is not entered (or modified). Key navigation using a hash key is limited to an equality key lookup (<code>d_keyfind</code> or SQL <b>where</b> clause using an equal comparison or <b>in</b> clause). </p><p>The <b>optional</b> attribute indicates that the data field is an <b>optional key</b>. <b>Optional key</b> values are not inserted into the key file until the application program calls function <code>d_keystore</code>. Optional keys can be manually deleted using function <code>d_keydel</code>. When an optional key is modified (through a <code>d_recwrite</code> or <code>d_crwrite</code> call), the key file will be updated only if the current value exists in the key file. </p><p MadCap:conditions="">Optional keys are often used to defer the overhead associated with storing keys to a time when the system is less busy. For example,  a certain kind of record which contains a key needs to be stored as rapidly as possible during the day. It may be defined as an optional key so that a batch program can be run to create the optional keys at night.</p><p MadCap:conditions="">Character string key fields are defined as "partial keys" if the value <i>key_dim</i> is smaller than the last array subscript <i>dim</i>. This means that the maximum size of the key values stored in the index will be smaller than the maximum field size. This reduces the physical size of the key files at the cost of performance, but does not otherwise affect the functionality of the field except for <code>d_keyread</code> which only will return the part of the key that is stored in the index file.
</p><p MadCap:conditions="">Fields of type <b>varchar</b> and <b>varwchar</b> are variable length fields. These data types are used in array definitions of string fields where a long maximum length is required, but where the field data actually stored will often be shorter than the maximum. <span class="MyVariablesProductShortName">RDM</span> will only allocate enough space in the database files for the data actually stored. This differs from the storage of <b>char</b> and <b>wchar_t</b> strings, where the defined maximum length is always allocated regardless of the data actually stored.
</p><p MadCap:conditions="">All <b>varchar</b> and <b>varwchar</b> fields are stored in <b>vardata</b> files. These files must be defined explicitly in the DDL schema.
</p><p>Fields declared as <b>struct</b> cannot be nested. Sub-fields of an arrayed <b>struct</b> field cannot be defined as key fields nor accessed individually. </p><p>Data fields of type <b>DB_ADDR</b> contain the database addresses of specific record occurrences in the database. Database addresses can be directly accessed using the currency table access functions described in <a href="Chapter5.htm#5.3">Currency Tables</a> section. This allows you to maintain your own record linkages directly, if desired. </p><p>Data fields will be aligned within the record in order to match the <b>struct</b> field alignment rules followed by your particular compiler and computer.</p><p>The <b>keylen</b> attribute allows the designer to limit the number of characters stored in the key file. A typical usage of this attribute would be to reduce the memory footprint of an inmemory key file or when indexing long string variables where it the first <b>keylen</b> characters are typically enough to determine position in the file.</p><p class="Heading">Examples: </p><pre>unique key char code[6]; </pre><p>Field <code>code</code> is a character string field of six characters long (five characters plus one null terminator) that is defined as a unique key. </p><pre MadCap:conditions="">unique key[16] varchar email[80]; 
</pre><p MadCap:conditions="">Field <code>email</code> is a variable length character string field. Its maximum length is eighty characters (including null terminator), but only the first sixteen characters are stored in the key file. This field is defined as a unique key, which means that its values must be unique over their whole length, not necessarily in the first sixteen characters. </p><pre xml:space="preserve">varchar description[32,256];</pre><p>The definition of a <b>varchar</b>, <b>varbinary</b> or <b>varwchar</b> field may contain a minimum length specifier. The minimum length definition (<b>minsize</b>)&#160;affects the internal storage of the data, but not the functionality of the field. The description field in the example above has a minimum length of 32 bytes, This is the number of bytes that will always be allocated in the record (in the data file) for this field, even if the field is empty. This value will always be rounded up to a multiple of 4 bytes.</p><pre>float balance; </pre><p>Field <code>balance</code> is a floating point field which, in the checking account database, contains a monetary value. </p><pre xml:space="preserve">key int check_date; </pre><p>Key field <code>check_date</code> is used to store a date in the application-defined Julian format (for example, number of elapsed days since January 1, 1900). Its values are stored on the key file in integer order. Thus, <code>check</code> records can be retrieved in check date order through use of the key retrieval functions (see <a href="Chapter5.htm#5.4.1">Data Retrieval Using Keys</a>). </p><pre xml:space="preserve">struct {
    double imag;
    double real;
} complex[3];</pre><p>This field statement defines a structure array field, <code>complex</code>, which stores an array of three complex numbers composed of an imaginary part and a real part. </p><pre>key long coordinates[3]; </pre><p>Field <code>coordinates</code> is an array of three long type variables and is also a key. It may be used to locate an object on a large three-dimensional grid. </p><pre>int bitmap; </pre><p>Field <code>bitmap</code> is used to store a bitmap of attribute flags, which are tested using binary operators and masks. For example, assuming this field was declared in record type <code>rec</code>, <code>rec.bitmap &amp; 0x0001</code> is non-zero if the low order bit is set. </p><p class="Notes"><span class="MyVariablesProductShortName">RDM</span> does not directly support C bit fields. </p><pre>char byte_array[16][1]; </pre><p>Byte array fields are implemented, as in <code>byte_array</code>, as a two-dimensional character array where the second dimension is one. This will force the <span class="MyVariablesProductShortName">RDM</span> runtime to manipulate all 16 bytes of the field rather than stopping at the first null byte as it does with string fields. </p><pre>DB_ADDR ptr_array[20]; </pre><p>Field <code>ptr_array</code> is an array of type <b>DB_ADDR</b>. It is used to store an array of the database addresses of record occurrences that are related to the record type in which <code>ptr_array</code> is defined. Use of <b>DB_ADDR</b> fields provides unlimited data organization possibilities to the programmer. However, these alternatives should only be used in those rare instances when the standard capabilities provided by keys and sets are insufficient for a particular requirement. </p><pre xml:space="preserve">optional key struct {
    char last_name[21];
    char first_name[21];
    char initial[2];
} name;</pre><p>Name is a <b>struct</b> field to contain person names and is composed of three string fields for the last and first names and the middle initial. <code>last_name</code> is the first field specified since, because name is a key field, the last name can be used in a partial key search to find, for example, all the <i>Smiths</i> on file. Thus, the order of the fields in a keyed <b>struct</b> field specifies the major and minor sort sequences for the key on the key file. </p><h4 class="Heading4"><a MadCap:generatedBookmark="TOC" name="Compound_Key_Fields"></a>Compound Key Fields </h4><p class="Heading">Syntax:</p><pre class="Grammar" xml:space="preserve">comkey_stmt:
                <b>compound</b> [<b>optional</b>] [<b>unique</b>] <b>key</b> [ '<b>[</b>' <i>keylen</i> '<b>]</b>' ] <i>keyname</i> '<b>{</b>'
                        <i>fldname</i> [<b>asc</b>[<b>ending</b>] |&#160;<b>desc</b>[<b>ending</b>]] '<b>;</b>'
                        [ <i>fldname</i> [<b>asc</b>[<b>ending</b>] |&#160;<b>desc</b>[<b>ending</b>]] '<b>;</b>' ]...
                '<b>}</b>' ['<b>;</b>']
        |&#160;      <b>compound hash</b> [ '<b>[</b>' <i>keylen</i> '<b>]</b>' ] <i>keyname</i> '<b>{</b>'
                        <i>fldname</i> '<b>;</b>'
                        [ <i>fldname</i> '<b>;</b>' ]...
               '<b>}</b>' ['<b>;</b>']</pre><p class="Heading" style="font-weight: bold;">Description: </p><p>The preceding syntax is used to define a compound key field named <i>keyname</i>. Compound keys are key field definitions consisting of any combination of fields (not necessarily contiguous) from a given record. Each sub-field of the compound key can be specified to be sorted in either ascending (default) or descending sequence. Compound keys differ from normal key fields in that they do not define additional data fields in the record. By using compound keys, you can have the same field appear in multiple keys within a record. </p><p>The compound key specifications must follow all other field statements in a record declaration. The order in which the sub-fields are specified determines the major and minor sort sequences. The <i>fldname</i> must be the name of a field that is defined in the record and is not defined as a <b>struct</b>. If the optional qualifier is specified, the key will only be stored when <code href="../RM/api/d_keystore.htm"><a href="../RM/api/d_keystore.htm">d_keystore</a></code> is called. Otherwise, the key is created when the record is created. All of the key functions that apply to normal key fields also apply to compound keys. </p><p><code><a href="../util/ddlp.htm">ddlp</a></code> will create in the <code>dbname.h</code> file a <b>struct</b> declaration named <code>keyname</code> for each compound key defined in the schema, similar to the struct declarations associated with records. These can be used in conjunction with the key manipulation functions of the <span class="MyVariablesProductShortName">RDM</span> runtime library. </p><p>Because of the nature of compound keys, records containing them can only be created using function <code><a href="../RM/api/d_fillnew.htm">d_fillnew</a></code> (not <code><a href="../RM/api/d_makenew.htm">d_makenew</a></code>). </p><p class="Heading">Examples: </p><pre xml:space="preserve">compound key tr_key {
    trdate descending;
    vendid ascending;
}
compound key ven_chks {
    vendid;
    checkno;
}</pre><p>Assume that a record type called trans contains two compound key definitions. Key <code>tr_key</code> is composed of fields <code>trdate</code> and <code>vendid</code>. Scanning through transaction records by <code>tr_key</code> would produce a sorted list in descending transaction date order, and ascending vendor id order within each date. Key <code>ven_chks</code> consists of two fields: <code>vendid</code> and <code>checkno</code>. Scanning through transaction records by <code>ven_chks</code> would give a sorted list in ascending vendor id order, and in ascending check number order within each vendor. </p><h3 class="Heading3"><a MadCap:generatedBookmark="TOC" name="4.2.6_Set_Declarations"></a>4.2.6 Set Declarations </h3><p class="Heading">Syntax: </p><pre class="Grammar" xml:space="preserve">set_stmt:
                <b>set</b>   <![CDATA[ ]]><i>setname</i>   <![CDATA[ ]]><b>{</b>   <![CDATA[
                        ]]><b>order</b> {<b>asc</b>[<b>ending</b>] |&#160;<b>desc</b>[<b>ending</b>] |&#160;<b>first</b>&#160;|&#160;<b>last</b> |&#160;<b>next</b>}&#160;'<b>;</b>'
                        <b>owner</b>   <![CDATA[ ]]><i>recname</i> '<b>;</b>'
                        member_stmt [member_stmt] ...
                <b>}</b></pre><pre class="Grammar" xml:space="preserve">member_stmt:
                <b>member</b>   <![CDATA[ ]]><i>recname</i> [ <b>by</b>   <![CDATA[ ]]><i>fldname</i>[, <i>fldname</i>...] ] '<b>;</b>'<br /></pre><p class="Heading">Description: </p><p>Set declarations define explicit, one-to-many relationships between record types. Sets are implemented as a linked list of member record instances connected to a single instance of an owner record, which serves as the root or head of the list. The order in which member records are inserted into this list is specified in the set order clause. </p><p>Possible set orderings are defined as follows: </p><table style="border-collapse: collapse;margin-left: 0;margin-right: auto;mc-table-style: url('../Resources/TableStyles/ArgsTwoCol.css');" class="TableStyle-ArgsTwoCol" cellspacing="0"><col class="Column-Column1" /><col class="Column-Column2" /><tr class="Body-Body1"><td class="BodyE-Column1-Body1">first </td><td class="BodyD-Column2-Body1">New member records are connected (that is, inserted) at the front of the list. </td></tr><tr class="Body-Body1"><td class="BodyE-Column1-Body1">last </td><td class="BodyD-Column2-Body1">New member records are connected at the end of the list. </td></tr><tr class="Body-Body1"><td class="BodyE-Column1-Body1">ascending </td><td class="BodyD-Column2-Body1">New member records are connected in ascending order based on the contents of the data fields specified in the by part of the member clause of the set statement. </td></tr><tr class="Body-Body1"><td class="BodyE-Column1-Body1">descending </td><td class="BodyD-Column2-Body1">New member records are connected in descending order based on the contents of the data fields specified in the by part of the member clause of the set statement. </td></tr><tr class="Body-Body1"><td class="BodyE-Column1-Body1">next </td><td class="BodyD-Column2-Body1">New member records are connected immediately following the current member of the set, or, if the current member is null, at the front of the list. </td></tr></table><p>The <b>by</b> part of the member clause is only supplied when ascending or descending order is specified. For sorted sets having more than one member record type, the sort field(s) of those record types should correspondingly be of the same type and length and be listed on the by clause in the same order. </p><p>When the sort field values of new member records of a sorted set duplicate existing members, the new members are added in front of the members with matching values.</p><p>The set owner may be specified as system. Use of the system record is not required. If one is used, do not declare it in a DDL record statement. <code><a href="../util/ddlp.htm">ddlp</a></code> automatically creates the system record when it is specified in a data file statement. There is only one occurrence of the system record in the database. It is used as the owner of any number of sets providing the means whereby records can be connected to the top or root of the network. When a database is opened, the current record and the current owner of all system-owned sets are initialized to the system record (see <a href="Chapter5.htm#5.3">Currency Tables</a>, for a discussion of currency). </p><p>Connecting member records to sets of order <b>first</b>, <b>last</b>, or <b>next</b> is faster than connecting to sets of order ascending or descending. This is because the list of member records associated with ascending or descending sets must be scanned each time a new member is connected, in order to find the proper insertion point. Thus, a connection to an ascending or descending set with a large number of members can be relatively slow. If you need a large sorted set, explore alternative approaches using keys or reverse ordering to maintain the ordering. </p><p class="Notes"><span class="MyVariablesProductShortName">RDM</span> does not implement ascending or descending sets through an index. As with all sets, they are implemented as a linked list (or chained) structure. <span class="MyVariablesProductShortName">RDM</span> does provide a keyed record access (through a B-tree index) but it is totally distinct from sets. A record can both have keys and be an owner and/or member of sets, but sets do not use keys and keys do not use sets. Thus, sort fields of ascending or descending sets do not need to be declared as key fields. </p><p class="Heading">Examples: </p><pre xml:space="preserve">set transactions {
    order last;
    owner budget;
    member check;
}</pre><p><code>transactions </code>is a set between the <code>budget</code> record and the <code>check</code> record in the checking account database. Each check written is to be applied to a particular budget account. Each budget account has a set of checks that have been written against it. As a new check is written and entered into the database, it is connected to the <code>transactions</code> set instance, where the appropriate budget record has been identified as the current owner of the set. The new check record will be connected to the end of the set. Thus (assuming checks are written in order), they will be stored in check number order (and probably date order as well). </p><p>To ensure that checks are stored in date order, the set specification could be modified as follows: </p><pre xml:space="preserve">set transactions {
    order ascending;
    owner budget;
    member check by check_date;
}                                                                                                      <![CDATA[ ]]></pre><p>Here the order has been changed to <code>ascending</code> and the member clause now includes the <code>by</code> part to indicate that the set is to be sorted on the <code>check_date</code> field of the <code>check</code> record. Again, the connect operation will be slower than if the order is last. However, if the sort field is known to usually force the insertion to be at the end of the set instance, the ordering of the set could be reversed so that the set remained sorted and so that the insertion was usually made quickly at the front of the list. </p><pre xml:space="preserve">set comment {
    order first;
    owner note;
    member project;
    member task;
    member work_day;
}</pre><p>The comment set illustrates a use of multiple member sets to reduce unnecessary space overhead. Each of the <code>project, task<span style="font-family: sans-serif;">, and</span> work_day</code> record types in a project management database can have an optional comment associated with it in the <code>note</code> record. In this example, an occurrence of <code>project, task, <span style="font-family: sans-serif;">or</span> work_day</code> can be associated with only a single occurrence of <code>note</code>. Thus each set instance is strictly one-to-one. Use of a single set is preferred over three separate sets because it will use less space for the set overhead (one set pointer is needed instead of three). See <a href="#4.4.2">Physical Design Considerations</a>, for more information.  </p><h2 class="Heading2"><a MadCap:generatedBookmark="TOC" name="4.3_DDL_Processor_Operation"></a><a name="4.3"></a>4.3 DDL Processor Operation </h2><h3 class="Heading3"><a MadCap:generatedBookmark="TOC" name="4.3.1_DDL_Processor_Execution"></a>4.3.1 DDL Processor Execution </h3><p>The Database Definition Language Processor, <a href="../util/ddlp.htm">ddlp</a>, is executed as follows: </p><pre MadCap:conditions="">ddlp [-c] [-d] [-r] [-x ] [-z] [-s [on/off]] ddlspec </pre><p>File <code>ddlspec</code> is the name of the text file containing the <a href="#4.2.1">DDL specification</a>. This file is sometimes called the schema file. </p><p>The <code><a href="../util/ddlp.htm">ddlp</a></code> will compile the DDL in file <code>ddlspec</code> and report any errors to stdout with the line number where the error was detected. </p><p>The compiled DDL is stored in the database dictionary file for use by the <span class="MyVariablesProductShortName">RDM</span> runtime library functions. The name of the dictionary is taken from the <b>dbname</b> of the database DDL statement and given an extension <code>.dbd</code>, forming <code><i>dbname</i>.dbd</code>. If no errors are detected, the dictionary file is stored in the database's directory within the <a href="Chapter3.htm#TFS">TFS</a> document root. Otherwise, the dictionary file is not created. </p><p MadCap:conditions="">If the <code>-c</code> option is specified, a "compilable" dictionary is created. This consists of a C source file containing the declaration of a statically initialized array, with the same contents as the file <code><i>dbname</i>.dbd</code>. You can include this C source file in your application, and pass the address of the array to the function <a href="../RM/api/d_open_ptr.htm">d_open_ptr</a> to open the database. This allows your application to open the database without using a dictionary file. </p><p>If the <code>-r</code> option is specified, <code>ddlp</code> will display (in stdout) the File Structure Report. (See <a href="#DDLP_Report">ddlp File Structure Report</a> for an explanation of the use of this report.) </p><p>If the <code>-x</code> option is given, a cross-reference listing of the records, fields, and set identifiers are displayed in stdout. An example report is shown below for the checking account schema. </p><pre xml:space="preserve">RDM <span class="MyVariablesReleaseVersion">11.0.0</span>, DDL X-Ref Listing of File: ckngacct.ddl
alloc                    field     11
amount                   field     20
balance                  field     12
budget                   record     3    7   26
cat_desc                 field     10
check                    record     3   15   27
check_date               field      5   18
check_no                 field      5   17
code                     field      4    9
paid_to                  field     19
transactions             set       23</pre><p>The names are listed in alphabetical order, with the associated type and the line numbers in the DDL file where the name is referenced. </p><p>With the <code>-d</code> option, <code>ddlp</code> allows duplicate field names, such that field types within different record types may have the same name. The record structures created by <code>ddlp</code> will contain the name as specified in the schema. The constant definitions for all fields will be a concatenation of the record type and field type, separated by an underscore. For example: </p><pre>record ticket {
	.
	.
	float unit_cost;
}
record invoice {
	.
	float unit_cost
}</pre><p>will cause the following constant definitions: </p><pre>#define TICKET_UNIT_COST 4005
#define INVOICE_UNIT_COST 6014</pre><p>If duplicate field names are used with key fields, then each reference to the key field name in the key file statement must have a prefix showing the record type that contains the field. The syntax is <code>recname.fldname</code>. </p><p><code>ddlp</code> creates C struct declarations for each record type and compound key field defined in the DDL and stored with file id, record, field, and set constants in a header file also named from the dbname of the database statement forming <code><i>dbname</i>.h</code>. By default, case is preserved on all of the names used. The <code>-s</code> option can be used to instruct <code>ddlp</code> to convert all of the names to lowercase to be compatible with previous versions. </p><p>The <code>ddlp</code> can process constants, #defines, predefined structures, and typedefs. All of these keywords must be used before <code>ddlp</code> recognizes the keyword <b>database</b>. Everything before the keyword <b>database</b> is copied to the resulting header file, so the application will not need to redefine anything. </p><p>As an example, the contents of file <code>ckngacct.h</code>, which was created when the checking account schema (as given in <a href="#4.2.1">DDL Basics</a>) was processed by <code>ddlp</code>, is shown below. </p><pre>#ifndef CKNGACCT_H
#define CKNGACCT_H
/*lint ++flb */

/* RDM <span class="MyVariablesReleaseVersion">11.0.0</span> */


/* database ckngacct record/key structure declarations */

struct budget {
   char code[6];
   char cat_desc[48];
   float alloc;
   float balance;
};

struct check {
   int32_t check_no;
   int32_t check_date;
   char paid_to[48];
   float amount;
};

/* record, field and set table entry definitions */

/* File Id Constants */
#define DATFILE 0
#define KEYFILE1 1
#define KEYFILE2 2

/* Record Name Constants */
#define BUDGET 10000
#define CHECK 10001

/* Field Name Constants */
#define CODE 0L
#define CAT_DESC 1L
#define ALLOC 2L
#define BALANCE 3L
#define CHECK_NO 1000L
#define CHECK_DATE 1001L
#define PAID_TO 1002L
#define AMOUNT 1003L

/* Set Name Constants */
#define TRANSACTIONS 20000

/* Field Sizes */
#define SIZEOF_CODE 6
#define SIZEOF_CAT_DESC 48
#define SIZEOF_ALLOC 4
#define SIZEOF_BALANCE 4
#define SIZEOF_CHECK_NO 4
#define SIZEOF_CHECK_DATE 4
#define SIZEOF_PAID_TO 48
#define SIZEOF_AMOUNT 4

/*lint --flb */
#endif    /* CKNGACCT_H */</pre><p>The <code>#define</code> constants are passed to runtime library functions to identify the particular file, record, field, or set type involved in the operation. The actual values represent entries into the tables that make up the database dictionary. The constants also have some additional control information encoded, as follows: </p><blockquote><p><i>Record name constants</i> consist of a record number (record 0 is the first record defined in the DDL, record 1 is the second, and so on) plus 10000. </p></blockquote><blockquote><p><i>Set name constants</i> consist of a set number (numbered sequentially, as are records) plus 20000. This information is used by <span class="MyVariablesProductShortName">RDM</span> runtime functions to distinguish between record and set constants. </p></blockquote><blockquote><p><i>Field name constants</i> are formed using the following formula:</p><blockquote><p style="font-style: italic;">(record number * 1000) + number of field within record</p></blockquote></blockquote><p>This can simplify the work involved in adding a new field to a record. With this technique, if a new field is only added to the end of a record, only those modules that need to reference the new field need to be recompiled.                                                   <![CDATA[ ]]></p><p>The <code>SIZEOF_??????</code> constants are added in the header file as a convenience of the user. If they are not needed, or are causing problems with large databases, they can be removed with a <cite style="font-style: normal;">-z</cite> option. </p><p class="Notes">Note that the database header file should be #included in every C source module that needs to access the database. </p><p>See <a href="../util/ddlp.htm">ddlp</a> for more options.</p><h3 class="Heading3"><a MadCap:generatedBookmark="TOC" name="4.3.2_ddlp_Alignment"></a>4.3.2 ddlp Alignment </h3><p>The structures defined in <code>dbname.h</code> may be used to store the contents of a record. When a variable is defined as a certain structure, the variable may be passed by reference to <span class="MyVariablesProductShortName">RDM</span> functions for storage into or retrieval from the database. The offsets of each element in the structure is dependent on how the compiler aligns structure elements. When <code>ddlp</code> is built with a certain compiler, it performs its own measurements on the compiler's alignments and uses those to compute offsets into the record's structure. Hence the offsets computed by <code>ddlp</code> and the offsets in the C structure should match up if the application program is built with the same compiler as <code>ddlp</code>. </p><p class="Heading">Nested Structures </p><p>Be very careful about using nested structures in records. The alignment of nested structures is very compiler-dependent. Although <span class="MyVariablesProductShortName">RDM</span> compensates for this dependence, <code>ddlp</code> may not always be able to produce the correct alignment of nested structures. </p><p>While numeric and character data can be included in the same record, we recommend that numeric data and character data not be mixed together. You should put the <code>double</code>s, <code>long</code>s, <code>int</code>s, and <code>short</code>s first, with the <code>char</code>s last. This will create the smallest possible records without artificially packing the structures and avoid most alignment problems. </p><p>If you plan to use nested structures, we recommend that they start on word boundaries (that is, with numeric data). Starting the structures on eight-byte boundaries may be necessary on some machines when the structures contain <code>double </code>data types. </p><h2 class="Heading2"><a MadCap:generatedBookmark="TOC" name="4.4_Database_Design_Considerations"></a>4.4 Database Design Considerations </h2><p>C programmers prefer the flexibility to make intelligent decisions based on a number of design alternatives, rather than having to rely on a less flexible system (which may do a lot more of our work for us, but not always in the way we want it done). Much of the power of <span class="MyVariablesProductShortName">RDM</span> stems from the flexibility it allows the application developer in organizing the database. This flexibility, however, requires the programmer to make design decisions from a wide variety of alternatives. </p><p>This section presents database design considerations as they pertain to <span class="MyVariablesProductShortName">RDM</span>. These design considerations are separated into logical design and physical design issues. Logical design (as defined here) involves those aspects of the database organization that directly affect the manner in which the C applications have to access and manipulate the stored information. Physical design addresses the organization of the database into data and key files and (except for file renaming and initialization) is transparent to the application program. </p><h3 class="Heading3"><a MadCap:generatedBookmark="TOC" name="4.4.1_Logical_Design_Considerations"></a><a name="4.4.1"></a>4.4.1 Logical Design Considerations </h3><p>The logical design considerations discussed here address the use of keys, sets, and multiple databases. Note that the examples given show only the DDL and not the actual code that uses it. The <a href="Chapter5.htm">Database Manipulation</a> section will complete many of these examples by providing the necessary code. </p><h4 class="Heading4"><a MadCap:generatedBookmark="TOC" name="Use_of_Keys"></a><a name="4.4.1.1"></a>Use of Keys </h4><h5><a MadCap:generatedBookmark="TOC" name="General_Key_Usage"></a>General Key Usage </h5><p>Key fields are basically used: </p><ul><li style="font-family: Arial;" value="1">To provide fast access to individual record occurrences </li><li style="font-family: Arial;" value="2">To provide efficiently sorted and selectable retrieval of a large number of record occurrences </li></ul><p>How is a specific record occurrence found among many? One could read and inspect each record occurrence in the order they were stored in the file, until the desired record is found. This would take some time if there are many occurrences. On average, half of the records on file would have to be inspected to find a specific record, and all would have to be inspected to determine that the record was not on file. </p><p>Alternatively, sets could be navigated through the network structure to locate the desired record (see <a href="#">Database Design</a>). This would generally mean that fewer records would have to be read, but the process still would be too slow, depending on the application requirements. </p><p>Because of the efficiency of the B-tree indexing method, locating a record through a key will involve at most only a few disk read operations (usually three or four). Thus, it is an ideal way to locate specific record occurrences rapidly. </p><p style="font-style: normal;">In <span class="MyVariablesProductShortName">RDM</span>, any field defined in a record can be a key except for <code>BLOB</code> data types. Thus there are a wide variety of potential ways to access a particular record. Fields can be defined as unique keys, to prevent the entry of records containing duplicate key values. Many record types will have a unique key when the key is used as a primary identifier of the record. These keys are also known as <i>primary keys</i>. When key fields are not defined as unique, records with duplicate keys are allowed to reside in the database. For example, zip code may be a key in a person record containing an address, but a record should not be excluded because another record has the same zip code value.</p><p>In the checking account database, <code>check_no</code> was defined as a unique key to allow the program to retrieve the check record for a particular check number. Other examples of data fields that would be good candidates for primary keys are: </p><ul><li style="font-family: Arial;" value="1">employee number </li><li style="font-family: Arial;" value="2">social security number </li><li style="font-family: Arial;" value="3">vehicle identification number </li><li style="font-family: Arial;" value="4">inventory item number </li><li style="font-family: Arial;" value="5">budget code </li><li style="font-family: Arial;" value="6">serial number </li><li style="font-family: Arial;" value="7">personal name                                                                                       </li></ul><p>Many different kinds of fields containing coded values are best implemented using a key. If new codes are needed, they can be added to the database without recompiling. For example, consider the following record declarations: </p><pre xml:space="preserve">/* vehicle make validation table */
record vehicle {
    unique key vma_code[7];    /* vehicle make code */
    char vma_desc[25];         /* vehicle make description */
}
/* vehicle fleet record */
record fleet {
    unique key char vin[25];   /* vehicle id number */
    char vma[5];               /* vehicle make */
    char vmo[5];               /* vehicle model */
    char vyr[3];               /* vehicle year */
    int lsd;                   /* last svc. date */
}</pre><p>An example vehicle record occurrence might be: </p><pre xml:space="preserve">vma_code:  CHEV 
vma_desc:  Chevrolet </pre><p>When a new <code>fleet</code> record is entered, the application program can easily validate that the <code>vma</code> field contains a correct code by doing a key find operation on its contents (specifics of how to do this are explained in <a href="Chapter5.htm#5.4.1">Data Retrieval Using Keys</a>). </p><p>The <code>check_date</code> field in the checking account database example was not a unique key. This provided the ability to write multiple checks with a common date and to quickly retrieve all checks written on a specific date or within a particular range of dates. </p><p>Key fields can also be used for rapid pattern-matching type searches. Many more keys than records can be retrieved in a single disk read. Use of a key field for certain search requirements will result in faster processing, especially when all occurrences need to be checked by the search operation. </p><p>For example, consider a law enforcement database containing "method of operation" records, which give the details of how specific crimes were committed. These records contain perhaps 25 data fields, each containing a numeric code identifying a particular aspect of the crime. One field in the record might describe a burglar's method of entry into a home as follows: </p><table style="width: 100%;border-left-style: solid;border-left-width: 1px;border-left-color: #c0c0c0;border-right-style: solid;border-right-width: 1px;border-right-color: #c0c0c0;border-top-style: solid;border-top-width: 1px;border-top-color: #c0c0c0;border-bottom-style: solid;border-bottom-width: 1px;border-bottom-color: #c0c0c0;border-collapse: collapse;margin-left: 0;margin-right: auto;mc-table-style: url('../Resources/TableStyles/BasicTwoCol.css');" class="TableStyle-BasicTwoCol" cellspacing="0"><col style="width: 127px;" class="Column-Column1" /><col class="Column-Column2" style="width: 843px;" /><thead><tr class="Head-Header1"><th class="HeadE-Column1-Header1">Code</th><th class="HeadD-Column2-Header1">Meaning</th></tr></thead><tbody><tr class="Body-Body1"><td class="BodyE-Column1-Body1">1 </td><td class="BodyD-Column2-Body1">Broke in through front door </td></tr><tr class="Body-Body1"><td class="BodyE-Column1-Body1">2 </td><td class="BodyD-Column2-Body1">Broke in through back door </td></tr><tr class="Body-Body1"><td class="BodyE-Column1-Body1">3 </td><td class="BodyD-Column2-Body1">Broke in through window </td></tr><tr class="Body-Body1"><td class="BodyE-Column1-Body1">4 </td><td class="BodyD-Column2-Body1">Picked front door lock </td></tr><tr class="Body-Body1"><td class="BodyE-Column1-Body1">5 </td><td class="BodyD-Column2-Body1">Picked back door lock </td></tr><tr class="Body-Body1"><td class="BodyE-Column1-Body1">6 </td><td class="BodyD-Column2-Body1">Came down the chimney </td></tr><tr class="Body-Body1"><td class="BodyB-Column1-Body1">7 </td><td class="BodyA-Column2-Body1">Other </td></tr></tbody></table><p>The reason for maintaining "method of operation"&#160;records in the database is, of course, to allow searches for a match of a selection of the fields. The key for the search would be a 25-element byte array in which each element's value would be a numeric code, with zero meaning "not supplied." </p><pre>record mo { &#160;&#160; 
	key char mo_data[25][1]; 
} </pre><p>The fields in the key would be ordered with the highest priority search field first and the lowest priority search field last. The highest priority search field is the one most often used in the searches. By listing it first, you can reduce the number of keys to be scanned in the maximum number of cases. If the first field is not used in the search, all keys must be scanned. </p><h5><a MadCap:generatedBookmark="TOC" name="Compound_Key_Usage"></a>Compound Key Usage </h5><p>In general, compound keys are used when one of the following conditions exists: </p><ul><li style="font-family: Arial;" value="1">A data field needs to participate in more than one key in the record. </li><li style="font-family: Arial;" value="2">A key is needed that contains multiple fields, where a mix of ascending and descending order is required among the sort fields. </li></ul><p>Note that non-compound keys do not require a descending order because that can be achieved by scanning them on the reverse order.</p><p>Suppose a record is to be searched based on the contents of two fields, where search values for either field are not always available. If a <code>struct</code> key field were used and the first field in the key was not available, all keys would need to be scanned. The use of two compound keys would solve the problem. </p><pre xml:space="preserve">record combo_search {
    int field1;
    int field2;
    compound key f1_1st {
        field1; field2;
    }
    compound key f2_1st {
        field2; field1;
    }
}</pre><p>If only <code>field1</code> data were available for the search, then key <code>f1_1st</code> would be scanned. If only <code>field2</code> data were supplied, then key <code>f2_1st</code> would be scanned. If both were supplied, by convention, <code>f1_1st</code> would be scanned. </p><p>Compound keys allow sort fields to be individually sorted in either ascending or descending order. Suppose in the checking account database we wanted to be able to list the checks sorted by the <code>paid_to field</code>, and, within that, in check number order with the most recent checks listed first, as in the following example : </p><pre xml:space="preserve">record check
{
    unique key int check_no;
    key int check_date;
    char paid_to[48];
    float amount;
    compound key pay_list
    {
        paid_to ascending;
        check_no descending;
    }
}</pre><h5><a MadCap:generatedBookmark="TOC" name="Optional_Key_Usage"></a>Optional Key Usage </h5><p>Optional keys are not created when the record is created, but only when specifically requested by the application program through the <code><a href="../RM/api/d_keystore.htm">d_keystore</a></code> function. </p><p>Optional keys should be used for fields that are not mandatory (the field's contents are not always supplied), but that need to be keyed when they are used. </p><p>Optional keys can also be used when it is desirable to defer the key creation to a time other than when the record is first stored. In real-time applications the number of record updates per a given time period (called the transaction rate) often needs to be maximized. Normally, the key fields in a record are created when the record is created, and this involves additional overhead of up to three or four disk input and output operations per key. The ability to defer key creation can greatly improve the transaction rate. Usually a separate program performs the key creation during non-peak system load times (for example, late at night). </p><h4 class="Heading4"><a MadCap:generatedBookmark="TOC" name="Use_of_Sets"></a><a name="4.4.1.2"></a>Use of Sets </h4><p>Set relationships form the basis of the network database model. The basic use of sets in forming one-to-many relationships was introduced in <a href="Chapter2.htm">Database Concepts</a> and illustrated in the checking account database example. This section will expand the use of sets by showing how they can be used to implement many-to-many relationships and variable-length records. </p><h5><a MadCap:generatedBookmark="TOC" name="Many-to-Many_Relationships"></a>Many-to-Many Relationships </h5><p>Many-to-many set relationships are best explained through an example. A typical example is students and classes in college. Each class has many students and each student takes many classes. Thus, there is a many-to-many relationship between classes and students. </p><p>Sets, however, only implement one-to-many relationships. On the surface, it might appear that the following <i>incorrect</i> implementation using two sets should work. </p><pre>record class {
	unique key char class_id[6];
	... other fields
}
record student {
	key char name[36];
	... other fields
}
set my_students {
	order last;
	owner class;
	member student;
}
set my_classes {
	order last;
	owner student;
	member class;
}                                                                                                   <![CDATA[ ]]></pre><p>The schema diagram in Figure 4-1 illustrates the relationships. </p><p class="Caption" style="text-align: left;"><img src="../Resources/Images/UsersGuide/UG-Fig-4-1_264x244.png" style="width: 264;height: 244;" /></p><p class="Caption" style="text-align: left;">Fig. 4-1. Incorrect Many-to-Many Implementation </p><p>The problem with this design is that a set member can have only one owner. Consider the following instance of the <b>my_students</b> set. </p><pre>Class: 		Computer Science 101 (CS101)
Students: 	Smith
		Jones
		Kelly
		Carlson</pre><p>A problem occurs when the <code>my_classes</code> set instances for these students is examined. Each student in CS101 must have that same class as a member of his <code>my_classes</code> set instance. This is not possible, however, since CS101 can only be connected to a single owner in the <code>my_classes</code> set. </p><p>The correct technique for implementing many-to-many relationships does indeed utilize two sets but through the use of an intersection record type, as follows: </p><pre xml:space="preserve">record class {
    unique key char class_id[6];
    ... other fields
}
record student {
    key char name[36];
    ... other fields
}
record intersect {
}
set my_students {
    order last;
    owner class;
    member intersect;
}
set my_classes {
    order last;
    owner student;
    member intersect;
}                                                                                                   <![CDATA[ ]]></pre><p>Figure 4-2 shows the schema diagram that corresponds to the above DDL. </p><p class="Caption"><img src="../Resources/Images/UsersGuide/UG-Fig-4-2_313x250.png" style="width: 313;height: 250;" /><br />Fig. 4-2. Correct Many-to-Many Implementation</p><p>Each <code>student</code> record occurrence will have its own set of <code>intersect</code> record occurrences through the <code>my_classes</code> set. Each of these <code>intersect</code> records is also owned by a specific <code>class</code> record through the <code>my_students</code> set. Similarly, each <code>class</code> record will have its own set of <code>intersect</code> record occurrences through the <code>my_students</code> set, each of which is owned by an individual <code>student</code> record through the <code>my_classes</code> set. </p><p>In this case the intersection record has no user-defined data in it. However, it could be an ideal place to store the student's grade for the class if that was needed. In that case you would probably want to change the name of the record type from <code>intersect</code> to <code>grade</code> or some other more meaningful name. </p><p>A description of the actual database manipulation involved in maintaining many-to-many relationships, based on the database design example presented in the <a href="#4.5">Database Design Example</a> section. </p><h4 class="Heading4"><a MadCap:generatedBookmark="TOC" name="Use_of_Multiple_Databases"></a>Use of Multiple Databases </h4><p>Application programs can open and access more than one database at a time. The use of multiple databases in an application can yield certain advantages and therefore should be a consideration in the design of the database. In this sense, an application's database may actually consist of several <span class="MyVariablesProductShortName">RDM</span> databases. </p><p>There are at least two situations in which multiple database design is useful: </p><ul><li style="font-family: Arial;" value="1">A temporary control or working database is desired </li><li style="font-family: Arial;" value="2">An application is to consist of optional, modular components </li></ul><p>Sometimes temporary application control information needs to be manipulated in sufficient quantities to benefit from the use of database operations on that data. This information can be stored in a temporary working database, which is initialized when the program begins and deleted when the program terminates. </p><p>An accounting package is a good example of a modular database application. Most such packages provide separate modules for various accounting functions. Companies only purchase the modules they need. A typical package would include these modules : </p><ul><li style="font-family: Arial;" value="1">General Ledger </li><li style="font-family: Arial;" value="2">Accounts Receivable </li><li style="font-family: Arial;" value="3">Accounts Payable </li><li style="font-family: Arial;" value="4">Payroll </li><li style="font-family: Arial;" value="5">Inventory </li><li style="font-family: Arial;" value="6">Sales Orders </li></ul><p>Almost all the modules require the general ledger module. The amount of shared information between the other modules depends on the application. </p><p>When designing an application that will use multiple databases, keep in mind that inter-database relationships can exist, but can only be implemented relationally through keys or through the use of <code>DB_ADDR</code> fields containing the database addresses of records in another database. It is not possible to have a set with an owner defined in one database and a member defined in another. However, an account number stored in the accounts receivable database can be used to find the associated account record in the general ledger. </p><h3 class="Heading3"><a MadCap:generatedBookmark="TOC" name="4.4.2_Physical_Design_Considerations"></a><a name="4.4.2"></a>4.4.2 Physical Design Considerations</h3><p class="Notes">Note: This section was written nearly 20 years ago, and the need to conserve disk space is less of an issue. Read this section if you are in a special environment where disk space is limited, or if in-memory databases are being used. Also, this section contains information useful to optimize processing performance.</p><p>This section describes those aspects of the physical characteristics of an <span class="MyVariablesProductShortName">RDM</span> database that can impact the disk space usage and access performance of an application program. An understanding of these physical implementation issues will help you design the most efficient databases possible under <span class="MyVariablesProductShortName">RDM</span>. </p><h4 class="Heading4"><a MadCap:generatedBookmark="TOC" name="The_RDM_File_Structure"></a>The <span class="MyVariablesProductShortName">RDM</span> File Structure </h4><p>Data and key files consist of pages, which contain a specific number of fixed-length record and key slots. Control information, as well as the normal record and key contents, are stored in these fixed-length slots. The size of the record and key slots in a file is based on the size of the largest record or key contained in that file. Smaller records or keys will of necessity contain unused slot space. </p><p>Database addresses (DB_ADDR) are 4 or 8 bytes long. The 4-byte addresses are direct pointers to any slot in a database consisting of up to 255 files, each with up to 16,777,215 slots. That is, 1 byte is used to identify a file, and 3 bytes are used to identify a slot. An 8-byte address uses 2 bytes to identify the file, and 6 bytes to identify a slot in the file.</p><p> The exact location of a slot is dependent on the database dictionary, as is the total potential size of the file.</p><p>The control information maintained by <span class="MyVariablesProductShortName">RDM</span> in a record is as follows: </p><ul><li style="font-family: Arial;" value="1">Record number (two bytes), required </li><li style="font-family: Arial;" value="2">Database address (four or eight bytes), required </li><li style="font-family: Arial;" value="3">Optional key bit maps (one byte for every eight optional keys defined in the record) </li><li style="font-family: Arial;" value="4">One set pointer (12 or 20 bytes, depending on DB_ADDR&#160;size) for each set for which record type is defined as an owner</li><li style="font-family: Arial;" value="5">One member pointer (12 or 24 bytes) for each set for which record type is defined as a member                                                                                      </li></ul><p>The amount of control information in a key is 10 or more bytes.</p><p>The information to be considered in database design is the space required for set and member pointers, as this is determined from the DDL.</p><h4 class="Heading4"><a MadCap:generatedBookmark="TOC" name="Record_and_Key_Placement"></a>Record and Key Placement </h4><p>The factors that dictate the optimal placement of records and keys into files are not always easy to determine, and are sometimes even mutually exclusive. Here are some "rules of thumb" to assist you. Some of these involve conflicting requirements. The best determination for your particular environment will be based on your own intuition supported by some testing, but ultimately through experience gained from actual use. </p><ul><li style="font-family: Arial;" value="1">Place dissimilar sized records and keys in separate files. </li><li style="font-family: Arial;" value="2">Minimizing the slot space that would be unused in the smaller records is the motivation for this guideline. </li><li style="font-family: Arial;" value="3">Place records and keys in separate files for better multi-user concurrency.                               </li></ul><p>The chances of multiple users locking the same file is increased when several record or key types are contained in the same file. Placing each key and record type in its own file will minimize access conflicts. </p><ul><li value="1">Place owner and member record types in the same file for improved set access performance. </li></ul><p>If new owner and member record occurrences are stored and connected in the same transaction and if they are located on the same file the likelihood of their being placed on the same database page is increased. This could yield better set access performance. </p><ul><li style="font-family: Arial;" value="1">Minimize the number of separate key files to improve cache performance. </li></ul><p>Caching is a technique in which frequently accessed database pages are kept in memory, thus reducing the amount of actual disk input and output required. Using fewer key files increases the probability that needed index pages will be in the cache. </p><ul><li style="font-family: Arial;" value="1">Experiment with the size of the pages to change the number of slots per page. </li></ul><p>Once the application is built, there will be only a fixed amount of memory left over that can be used for the <span class="MyVariablesProductShortName">RDM</span> cache. Some applications get better performance from a smaller number of larger-sized pages that contain more slots per page. Other applications get better performance from a larger number of smaller-sized pages that contain fewer slots per page. </p><h4 class="Heading4"><a MadCap:generatedBookmark="TOC" name="ddlp_File_Structure_Report"></a><a name="DDLP_Report"></a>ddlp File Structure Report </h4><p>The File Structure Report is produced by using the <code>-r</code> option on the <a href="../util/ddlp.htm">ddlp</a> command line. This report summarizes the physical characteristics for each file and record type defined in the DDL. The report produced for the checking account database is given below. </p><pre xml:space="preserve">
RDM&#160;<span class="MyVariablesReleaseVersion">11.0.0</span>, Summary of Database: ckngacct
FILE: chkg.dat
   Id  : 0
   Type: data
   Size of record slots : 82
   Record slots per page: 6
   Unused page space    : 16

FILE: chkg.k01
   Id  : 1
   Type: key
   Size of record slots : 16
   Record slots per page: 63
   Unused page space    : 6

FILE: chkg.k02
   Id  : 2
   Type: key
   Size of record slots : 14
   Record slots per page: 145
   Unused page space    : 8

RECORD: budget
   Id  : 0
   File: chkg.dat [0]
   Total set pointers   : 1
   Total member pointers: 0
   Offset to data       : 18
   Size of record       : 82
   Unused slot space    : 0

RECORD: check
   Id  : 1
   File: chkg.dat [0]
   Total set pointers   : 0
   Total member pointers: 1
   Offset to data       : 18
   Size of record       : 78
   Unused slot space    : 4
</pre><p>The summary for each data and key file includes the following: </p><ul><li style="font-family: Arial;" value="1">File name </li><li style="font-family: Arial;" value="2">File id number </li><li style="font-family: Arial;" value="3">File type: data or key </li><li style="font-family: Arial;" value="4">Size of each record or key slot in bytes </li><li style="font-family: Arial;" value="5">Total number of slots per page </li><li style="font-family: Arial;" value="6">Total amount of unused page space</li></ul><p>The information most significant to database design is the number of slots per page and the amount of unused page space in a data file. The unused page space occurs because the slot size multiplied by the number of slots per page does not always exactly equal the size of the database page. Much of this unused space can be reserved by adding an extra (unused) data field to the largest record on the file. The length of the field is computed as follows: </p><blockquote><p style="font-style: italic;">length = (unused page space) / (slots per page) </p></blockquote><p>The unused space is contained in a record so that if additional data needs to be stored in that record, space will be available. If the reserved space is large enough, the new field can be added without restructuring the database. </p><p>The record summary contains the following information. </p><ul><li style="font-family: Arial;" value="1">Record name </li><li style="font-family: Arial;" value="2">Record number </li><li style="font-family: Arial;" value="3">File in which record is contained </li><li style="font-family: Arial;" value="4">Total number of set pointers (sets owned by record) </li><li style="font-family: Arial;" value="5">Total number of member pointers (sets in which record is member) </li><li style="font-family: Arial;" value="6">Offset to start of data from start of record </li><li style="font-family: Arial;" value="7">Total size of record in bytes </li><li style="font-family: Arial;" value="8">Amount of unused slot space</li></ul><p>The design-related information in this report is the unused slot space. This space can easily be converted into a usable form by adding an extra field the length of the unused slot space to the record. Then, as explained above, the space is available for additional data to be stored in the record at a later date, without requiring a restructure of the database. </p><p>Also important in calculating the size of the records is the or<span class="MyVariablesProductShortName">RDM</span>dering and size of the data types used in the record. Most systems require numeric data to start on word boundaries. This means that if the field preceding a numeric field does not end on a word boundary, unseen and unusable padding is inserted to force the numeric data to the word boundary. When character and numeric data are not carefully mixed, wasted space can be generated. </p><h4 class="Heading4"><a MadCap:generatedBookmark="TOC" name="File_Page_Sizes"></a>File Page Sizes </h4><p>To optimize file access performance, the page sizes for data and key files should be a multiple of the file block size used by your operating system. Many systems have a block size of 512 bytes. In these systems block sizes of 512, 1024, 1536, etc. would be acceptable. </p><p>The best page size for a given file is not always easily determined, and will be based on application implementation details. Key file pages should be large enough to hold a reasonable number of keys, so that the number of levels in the resulting B-tree are kept as small as possible (less than or equal to four). Data file page sizes should be based on the number of records you want to store on each page. For example, if all members of a set are stored together, then they will likely be stored in contiguous record slots. If they will usually be accessed together as well, then you may decide that the page size should be large enough to hold the average number of set members in order to minimize the actual disk accesses necessary to read each member. </p><p>The initial <span class="MyVariablesProductShortName">RDM</span> runtime page buffers are sized based upon the largest page size specified in the DDL. For example, if you have specified four files with a 1024-byte page size and one file with a 4096-byte page size, <span class="MyVariablesProductShortName">RDM</span> will allocate 4096 bytes for each page in the cache. You need to be aware of your memory requirements in deciding on page sizes. </p><h2 class="Heading2"><a MadCap:generatedBookmark="TOC" name="4.5_Database_Design_Example"></a><a name="4.5"></a>4.5 Database Design Example </h2><h3 class="Heading3"><a MadCap:generatedBookmark="TOC" name="4.5.1_Introduction"></a>4.5.1 Introduction </h3><p>The example to be presented in this section is an elaboration of the <code>tims</code> database introduced in <a href="Chapter3.htm">Database Design</a>. It will be used in examples throughout the remainder of this document. A solid understanding of this example design is necessary. </p><p>The requirements for the TIMS application are given first, followed by a description of the schema with explanations of how the design will be used to satisfy the stated requirements. </p><h3 class="Heading3"><a MadCap:generatedBookmark="TOC" name="4.5.2_Requirements"></a>4.5.2 Requirements </h3><p>The system is to be used to maintain a database of technical information contained in books, technical journals or magazines, and articles. In the following discussion, a single book, journal issue, or article will be generally referred to as an info item. </p><p>The following data is to be stored for each book, journal, or article: </p><ul><li style="font-family: Arial;" value="1">author's name </li><li style="font-family: Arial;" value="2">information id code </li><li style="font-family: Arial;" value="3">title </li><li style="font-family: Arial;" value="4">publisher </li><li style="font-family: Arial;" value="5">date published </li><li style="font-family: Arial;" value="6">abstract </li><li style="font-family: Arial;" value="7">topical key words</li></ul><p>The id code will be a unique Dewey-Decimal library code assigned by the user. The abstract will be a brief description (up to several paragraphs) of the info item. Each info item may have several key words associated with it that identify topics discussed in it. </p><p>Functions are to be provided to allow info item entry and deletion. </p><p>The info item data is to be retrieved as follows: </p><ul><li style="font-family: Arial;" value="1">By author name, where all info items for a given author are reported </li><li style="font-family: Arial;" value="2">By id code, through which individual occurrences can be found or all occurrences can be retrieved in id code order </li><li style="font-family: Arial;" value="3">By key word, where all info items for a given key word are reported </li></ul><p>The ability to keep track of loaned books and magazines is also to be provided, where the borrower's name, the date borrowed, and the date returned are stored for each item loaned. A loan history is to be maintained for each info item. In addition, the ability to report all unreturned info items is to be provided. </p><h3 class="Heading3"><a MadCap:generatedBookmark="TOC" name="4.5.3_Using_a_System_Record"></a>4.5.3 Using a System Record</h3><p>This design uses a <code>system</code> record. The system record exists in this database because it is named as the owner of two set types, <code>author_list</code> and <code>loan_history</code>. Only one system record can exist in a database, but it must still be placed into one of the data files. It is not efficient to place the system record into its own file (even though it will work), because there is only one system record.</p><p>A system record is not required in any database. Historically, a sorted system set was a way to declare the existence of an index. Since <span class="MyVariablesProductShortName">RDM</span> declares indexes in other ways, a system set is not an essential access method. What is the benefit of a system owned set when keys can also work?</p><p>In this database design, it is anticipated that there will be a relatively small number of author records. So the system set ordered by author name requires less space because it requires no key file.</p><p>The loan history can also be implemented through an index, but in our design, the member record type, borrower, is not sorted. This means that the program is free to establish the order of the loan history through connecting each new borrower record in the location of its choice (in this case, last).</p><p>In summary, a system-owned set may be preferable to a key when a small number of members will exist, or when customized ordering is preferred.</p><h3 class="Heading3"><a MadCap:generatedBookmark="TOC" name="4.5.4_Database_Design"></a>4.5.4 Database Design </h3><p>The schema diagram for the database design is shown in Figure 4-5 below. </p><p class="Caption"><img src="../Resources/Images/UsersGuide/UG-Fig-4-5.png" /><br />Fig. 4-5. TIMS Database Schema</p><p>The principal data for each info item is stored in a record called info. This includes the id code, title, publisher, and publication date. Also included is a coded-value field for storing the type of info, where 0 = book, 1 = journal or magazine and 2 = article. The id code will be a key in order to quickly find specific info occurrences. </p><p>Because there may be many books or articles written by a single author, storing the author name in the info record would replicate multiple occurrences of the same author. This is often referred to as redundant data. So, the author is stored in a separate record with a set, has_published, connecting an author to that author's info records. </p><p>Since the <code>info</code> records for a given author are to be retrievable by author name, a set, ordered by author name, called <code>author_list</code>, has been defined with the system record as the owner. To find a specified author, this set is searched. This is sufficient for a small personal library where there would be relatively few authors (less than 100) and the system is only used by a single user. In a large library with many authors, access would be faster if we used the author name as a key field and did not use a set. Here (mainly for instructional purposes), the assumption is that the system is for a small, personal library. </p><p>A simple variable-length text structure is used for storing the abstract. A record type called text is defined that stores a text string of up to 80 characters, including a sentinel null byte. A set called abstract with order <code>last</code> is defined with <code>info</code> as owner and <code>text</code> as member, forming a one-to-many set between an info record and each line of abstract text. </p><p>The relationship between key words and item <code>info</code> records is many-to-many. A key word is stored in a record type named <code>key_word</code>. The key word is a string field that is keyed to allow rapid retrieval of individual key word occurrences and to allow alphabetized key word perusal. The many-to-many relationship is implemented through the use of two sets, as described in "Logical Design Considerations." Key_word records and info records are connected to an intersection record called <code>intersect</code>. Set <code>key_to_info</code> is used to find the info records corresponding to a particular key word. Set <code>info_to_key</code> is used to find the key words associated with a given info record. The intersect record has one field to hold a copy of the info type from its info owner through the info_to_key set. By eliminating an extra disk read of the info record for non-books, this facilitates the kind of key word searches where, for example, you're only interested in finding the books covering a specific topic. Redundant data is sometimes incorporated into a database design in order to improve data access performance. </p><p>A record type named borrower will contain the name of the <code>borrower</code>, the date loaned, and the date returned. The borrower's name will be a key field, in order to be able to quickly find all of the items borrowed by a particular person. Dates will be stored as a long integer of the form YYMMDD (for example, 870709 is July 9, 1987). A date of zero indicates that the loaned item has not yet been returned. When an item is loaned, a new borrower record is created and is connected to two sets. A set called <code>loaned_books</code> connects the borrower record to the info record for the loaned item. These records will normally remain members of this set even after the item is returned, to maintain a loan history for each item in the library. The <code>borrower</code> record is also connected to a set called loan_history, which is owned by the system record. This set is scanned when a list of all unreturned books is desired. Both sets are in last order so the records will be connected in chronological order (without having to specify ascending order by date loaned). </p><p>One final set has been included. The set named <code>article_list</code> has info records participating as both owner and member of the same set (which is legal in <span class="MyVariablesProductShortName">RDM</span>). Here, the set is intended to connect article info records to the info record of the journal or magazine in which it is published. </p><p>The <span class="MyVariablesProductShortName">RDM</span> DDL that implements the TIMS database design is presented on the next page. Two data files and two key files have been defined. Data file <code>tims.d01</code> contains the system record (of which there is only one occurrence and is small because it has no fields), <code>key_word</code> records and <code>intersect</code> records. Data file <code>tims.d02</code> contains the occurrences of record types <code>author</code>, <code>borrower</code>, <code>info</code>, and <code>text</code>. This organization is arbitrary in this case since the database is not large. </p><p>Key field <code>id_code</code> is smaller than keys <code>friend</code> and <code>word</code> and is therefore stored in a separate key file, as is shown in the example below. </p><pre>/*-------------------------------------------------------------------
Technical Information Management System (TIMS) Database
--------------------------------------------------------------------*/
database tims
{
    data file "tims.d01" contains system, key_word, intersect;
    data file "tims.d02" contains author, borrower, info, text;
    key file  "tims.k01" contains id_code;
    key file  "tims.k02" contains friend, word;

    record author {
        char name[32];               /* author's name: "last, first" */
    }                                /* or editor's name */
    record info {
        unique key char id_code[16]; /* dewey dec. code */
        char info_title[80];         /* title of book, article, mag. */
        char publisher[32];          /* name of publisher */
        char pub_date[12];           /* date of publication */
        int16_t info_type;           /* 0=book, 1=mag, 2=art */
    }
    record borrower {
        key char friend[32];         /* name of borrower */
        long date_borrowed;          /* dates are stored initially */
        long date_returned;          /* numeric YYMMDD */
    }
    record text {
        char line[80];               /* line of abstract text */
    }
    record key_word {
        unique key char word[32];    /* subject key words */
    }
    record intersect {
        int16_t int_type;            /* copy of info_type */
    }
    set author_list {
        order ascending;
        owner system;
        member author by name;
    }
    set has_published {
        order ascending;
        owner author;
        member info by info_title;
    }
    set articles {
        order last;
        owner info;
        member info;
    }
    set loaned_books {
        order last;
        owner info;
        member borrower;
    }
    set abstract {
        order last;
        owner info; 
        member text;
    }
    set key_to_info {
        order last;
        owner key_word;
        member intersect;
    }
    set info_to_key {
        order last;
        owner info;
        member intersect;
    }
    set loan_history {
        order last;
        owner system;
        member borrower;
    }
}</pre><hr MadCap:conditions="Default.ScreenOnly" width="100%" size="0" align="center" /><p MadCap:conditions="Default.ScreenOnly" style="font-size: 8pt;"><span class="MyVariablesCopyright">Copyright © 2012, Raima Inc. All rights reserved.</span></p><script type="text/javascript" src="../SkinSupport/MadCapBodyEnd.js"></script><p class="MCWebHelpFramesetLink MCWebHelpFramesetLinkBottom" style="display: none;"><a href="../../Default_CSH.htm#UG/Chapter4.htm" style="">Open topic with navigation</a></p></body>
</html>